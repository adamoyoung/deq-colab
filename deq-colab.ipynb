{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deq-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install flax optax"
      ],
      "metadata": {
        "id": "si6WmYzuEMsO",
        "outputId": "ff2ccd3e-b3a9-471e-c90a-fd223290c3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: jax>=0.3 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.0.0)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.2+cuda11.cudnn805)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.3->flax) (1.15.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "Ukan3mN8mwVX"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import jax.lax as lax\n",
        "from jax import random, jit\n",
        "\n",
        "import optax\n",
        "\n",
        "import flax\n",
        "from flax import linen as nn\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import numpy as np  # TO DO remove np's -> jnp\n",
        "import contextlib\n",
        "\n",
        "from typing import Tuple, Union, List, OrderedDict, Callable, Any\n",
        "from dataclasses import field\n",
        "\n",
        "# jaxopt has already implicit differentiation!!\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function for local random seeding\n",
        "@contextlib.contextmanager\n",
        "def np_temp_seed(seed):\n",
        "\tstate = np.random.get_state()\n",
        "\tnp.random.seed(seed)\n",
        "\ttry:\n",
        "\t\tyield\n",
        "\tfinally:\n",
        "\t\tnp.random.set_state(state)"
      ],
      "metadata": {
        "id": "aIIhg_O_xVGC"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEQ idea & finding stationary points with root finder, maybe root finder demo on small example (but that's close to copying from last year so maybe smth different?)"
      ],
      "metadata": {
        "id": "lEX0Pf1IGH2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _safe_norm_jax(v):\n",
        "    if not jnp.all(jnp.isfinite(v)):\n",
        "        return jnp.inf\n",
        "    return jnp.linalg.norm(v)\n",
        "\n",
        "def scalar_search_armijo_jax(phi, phi0, derphi0, c1=1e-4, alpha0=1, amin=0):\n",
        "    ite = 0\n",
        "    phi_a0 = phi(alpha0)    # First do an update with step size 1\n",
        "    if phi_a0 <= phi0 + c1*alpha0*derphi0:\n",
        "        return alpha0, phi_a0, ite\n",
        "\n",
        "    # Otherwise, compute the minimizer of a quadratic interpolant\n",
        "    alpha1 = -(derphi0) * alpha0**2 / 2.0 / (phi_a0 - phi0 - derphi0 * alpha0)\n",
        "    phi_a1 = phi(alpha1)\n",
        "\n",
        "    # Otherwise loop with cubic interpolation until we find an alpha which\n",
        "    # satisfies the first Wolfe condition (since we are backtracking, we will\n",
        "    # assume that the value of alpha is not too small and satisfies the second\n",
        "    # condition.\n",
        "    while alpha1 > amin:       # we are assuming alpha>0 is a descent direction\n",
        "        factor = alpha0**2 * alpha1**2 * (alpha1-alpha0)\n",
        "        a = alpha0**2 * (phi_a1 - phi0 - derphi0*alpha1) - \\\n",
        "            alpha1**2 * (phi_a0 - phi0 - derphi0*alpha0)\n",
        "        a = a / factor\n",
        "        b = -alpha0**3 * (phi_a1 - phi0 - derphi0*alpha1) + \\\n",
        "            alpha1**3 * (phi_a0 - phi0 - derphi0*alpha0)\n",
        "        b = b / factor\n",
        "\n",
        "        alpha2 = (-b + jnp.sqrt(jnp.abs(b**2 - 3 * a * derphi0))) / (3.0*a)\n",
        "        phi_a2 = phi(alpha2)\n",
        "        ite += 1\n",
        "\n",
        "        if (phi_a2 <= phi0 + c1*alpha2*derphi0):\n",
        "            return alpha2, phi_a2, ite\n",
        "\n",
        "        if (alpha1 - alpha2) > alpha1 / 2.0 or (1 - alpha2/alpha1) < 0.96:\n",
        "            alpha2 = alpha1 / 2.0\n",
        "\n",
        "        alpha0 = alpha1\n",
        "        alpha1 = alpha2\n",
        "        phi_a0 = phi_a1\n",
        "        phi_a1 = phi_a2\n",
        "\n",
        "    # Failed to find a suitable step length\n",
        "    return None, phi_a1, ite\n",
        "\n",
        "\n",
        "def line_search_jax(update, x0, g0, g, nstep=0, on=True):\n",
        "    \"\"\"\n",
        "    `update` is the propsoed direction of update.\n",
        "\n",
        "    Code adapted from scipy.\n",
        "    \"\"\"\n",
        "    tmp_s = [0]\n",
        "    tmp_g0 = [g0]\n",
        "    tmp_phi = [jnp.linalg.norm(g0)**2]\n",
        "    s_norm = jnp.linalg.norm(x0) / jnp.linalg.norm(update)\n",
        "\n",
        "    def phi(s, store=True):\n",
        "        if s == tmp_s[0]:\n",
        "            return tmp_phi[0]    # If the step size is so small... just return something\n",
        "        x_est = x0 + s * update\n",
        "        g0_new = g(x_est)\n",
        "        phi_new = _safe_norm_jax(g0_new)**2\n",
        "        if store:\n",
        "            tmp_s[0] = s\n",
        "            tmp_g0[0] = g0_new\n",
        "            tmp_phi[0] = phi_new\n",
        "        return phi_new\n",
        "    \n",
        "    if on:\n",
        "        s, phi1, ite = scalar_search_armijo_jax(phi, tmp_phi[0], -tmp_phi[0], amin=1e-2)\n",
        "    if (not on) or s is None:\n",
        "        s = 1.0\n",
        "        ite = 0\n",
        "\n",
        "    x_est = x0 + s * update\n",
        "    if s == tmp_s[0]:\n",
        "        g0_new = tmp_g0[0]\n",
        "    else:\n",
        "        g0_new = g(x_est)\n",
        "    return x_est, g0_new, x_est - x0, g0_new - g0, ite\n",
        "\n"
      ],
      "metadata": {
        "id": "F9GgbTf2Vbt_"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmatvec_jax(part_Us, part_VTs, x):\n",
        "    # Compute x^T(-I + UV^T)\n",
        "    # x: (N, 2d, L')\n",
        "    # part_Us: (N, 2d, L', threshold)\n",
        "    # part_VTs: (N, threshold, 2d, L')\n",
        "    if jnp.size(part_Us) == 0:\n",
        "        return -x\n",
        "    xTU = jnp.einsum('bij, bijd -> bd', x, part_Us)   # (N, threshold)\n",
        "    return -x + jnp.einsum('bd, bdij -> bij', xTU, part_VTs)    # (N, 2d, L'), but should really be (N, 1, (2d*L'))\n",
        "\n",
        "def matvec_jax(part_Us, part_VTs, x):\n",
        "    # Compute (-I + UV^T)x\n",
        "    # x: (N, 2d, L')\n",
        "    # part_Us: (N, 2d, L', threshold)\n",
        "    # part_VTs: (N, threshold, 2d, L')\n",
        "    if jnp.size(part_Us) == 0:\n",
        "        return -x\n",
        "    VTx = jnp.einsum('bdij, bij -> bd', part_VTs, x)  # (N, threshold)\n",
        "    return -x + jnp.einsum('bijd, bd -> bij', part_Us, VTx)     # (N, 2d, L'), but should really be (N, (2d*L'), 1)\n"
      ],
      "metadata": {
        "id": "DpQtBBHPV36I"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def broyden_jax(f, z0, x0, threshold, eps=1e-3, stop_mode=\"rel\", result_dict=False, ls=False):\n",
        "    bsz, total_hsize = z0.shape\n",
        "    orig_shape = (bsz,total_hsize)\n",
        "    seq_len = 1\n",
        "    new_shape = (bsz,total_hsize,seq_len)\n",
        "    z0 = z0.reshape(*new_shape)\n",
        "    def g(_z):\n",
        "        # here it is safe to use x out of scope\n",
        "        return (f(_z.reshape(*orig_shape),x0)-_z.reshape(*orig_shape)).reshape(*new_shape)\n",
        "    dev = z0.device()\n",
        "    alternative_mode = 'rel' if stop_mode == 'abs' else 'abs'\n",
        "    \n",
        "    z_est = z0           # (bsz, 2d, L')\n",
        "    gz = g(z_est)        # (bsz, 2d, L')\n",
        "    nstep = 0\n",
        "    tnstep = 0\n",
        "    \n",
        "    # For fast calculation of inv_jacobian (approximately)\n",
        "    Us = jax.device_put(jnp.zeros((bsz, total_hsize, seq_len, threshold)),dev)     # One can also use an L-BFGS scheme to further reduce memory\n",
        "    VTs = jax.device_put(jnp.zeros((bsz, threshold, total_hsize, seq_len)),dev)\n",
        "    update = -matvec_jax(Us[:,:,:,:nstep], VTs[:,:nstep], gz)      # Formally should be -torch.matmul(inv_jacobian (-I), gx)\n",
        "    prot_break = False\n",
        "    \n",
        "    # To be used in protective breaks\n",
        "    protect_thres = (1e6 if stop_mode == \"abs\" else 1e3) * seq_len\n",
        "    new_objective = 1e8\n",
        "\n",
        "    trace_dict = {'abs': [],\n",
        "                  'rel': []}\n",
        "    lowest_dict = {'abs': 1e8,\n",
        "                   'rel': 1e8}\n",
        "    lowest_step_dict = {'abs': 0,\n",
        "                        'rel': 0}\n",
        "    nstep, lowest_zest, lowest_gz = 0, z_est, gz\n",
        "\n",
        "    while nstep < threshold:\n",
        "        z_est, gz, delta_z, delta_gz, ite = line_search_jax(update, z_est, gz, g, nstep=nstep, on=ls)\n",
        "        nstep += 1\n",
        "        tnstep += (ite+1)\n",
        "        abs_diff = jnp.linalg.norm(gz)\n",
        "        rel_diff = abs_diff / (jnp.linalg.norm(gz + z_est) + 1e-9)\n",
        "        diff_dict = {'abs': abs_diff,\n",
        "                     'rel': rel_diff}\n",
        "        trace_dict['abs'].append(abs_diff)\n",
        "        trace_dict['rel'].append(rel_diff)\n",
        "        for mode in ['rel', 'abs']:\n",
        "            if diff_dict[mode] < lowest_dict[mode]:\n",
        "                if mode == stop_mode: \n",
        "                    lowest_zest, lowest_gz = jnp.copy(z_est), jnp.copy(gz)\n",
        "                lowest_dict[mode] = diff_dict[mode]\n",
        "                lowest_step_dict[mode] = nstep\n",
        "\n",
        "        new_objective = diff_dict[stop_mode]\n",
        "        if new_objective < eps: break\n",
        "        if new_objective < 3*eps and nstep > 30 and np.max(trace_dict[stop_mode][-30:]) / np.min(trace_dict[stop_mode][-30:]) < 1.3:\n",
        "            # if there's hardly been any progress in the last 30 steps\n",
        "            break\n",
        "        if new_objective > trace_dict[stop_mode][0] * protect_thres:\n",
        "            prot_break = True\n",
        "            break\n",
        "\n",
        "        part_Us, part_VTs = Us[:,:,:,:nstep-1], VTs[:,:nstep-1]\n",
        "        vT = rmatvec_jax(part_Us, part_VTs, delta_z)\n",
        "        u = (delta_z - matvec_jax(part_Us, part_VTs, delta_gz)) / jnp.einsum('bij, bij -> b', vT, delta_gz)[:,None,None]\n",
        "        vT = jnp.nan_to_num(vT,nan=0.)\n",
        "        u = jnp.nan_to_num(u,nan=0.)\n",
        "        VTs = VTs.at[:,nstep-1].set(vT)\n",
        "        Us = Us.at[:,:,:,nstep-1].set(u)\n",
        "        update = -matvec_jax(Us[:,:,:,:nstep], VTs[:,:nstep], gz)\n",
        "\n",
        "    # Fill everything up to the threshold length\n",
        "    for _ in range(threshold+1-len(trace_dict[stop_mode])):\n",
        "        trace_dict[stop_mode].append(lowest_dict[stop_mode])\n",
        "        trace_dict[alternative_mode].append(lowest_dict[alternative_mode])\n",
        "\n",
        "    lowest_zest = lowest_zest.reshape(*orig_shape)\n",
        "    # print(\"broyden\",jnp.linalg.norm(z_est),jnp.linalg.norm(gz))\n",
        "\n",
        "    if result_dict:\n",
        "        return {\"result\": lowest_zest,\n",
        "                \"lowest\": lowest_dict[stop_mode],\n",
        "                \"nstep\": lowest_step_dict[stop_mode],\n",
        "                \"prot_break\": prot_break,\n",
        "                \"abs_trace\": trace_dict['abs'],\n",
        "                \"rel_trace\": trace_dict['rel'],\n",
        "                \"eps\": eps,\n",
        "                \"threshold\": threshold}\n",
        "    else:\n",
        "        return lowest_zest\n",
        "\n",
        "\n",
        "def newton_jax(f, z0, x0, threshold, eps=1e-3):\n",
        "    # TODO replace with jax while\n",
        "\n",
        "    # note: f might ignore x0 (i.e. with backward pass)\n",
        "    orig_shape = z0.shape\n",
        "    def g(_z):\n",
        "      # this reshaping is to enable solving with Jacobian\n",
        "      return (f(_z.reshape(*orig_shape),x0)-_z.reshape(*orig_shape)).reshape(-1)\n",
        "    jac_g = jax.jacfwd(g)\n",
        "    z = z0.reshape(-1)\n",
        "    gz = g(z)\n",
        "    gz_norm = jnp.linalg.norm(gz)\n",
        "    nstep = 0\n",
        "\n",
        "    while nstep < threshold and gz_norm > eps:\n",
        "      # solve system\n",
        "      jgz = jac_g(z)\n",
        "      # print(\"gz\",gz.shape,jnp.linalg.norm(gz))\n",
        "      # print(\"jgz\",jgz.shape,jnp.linalg.norm(jgz))\n",
        "      delta_z = jnp.linalg.solve(jgz,-gz)\n",
        "      # print(\"delta_z\",delta_z.shape,jnp.linalg.norm(delta_z))\n",
        "      z = z + delta_z\n",
        "      # need to compute gx here to decide whether to stop\n",
        "      gz = g(z)\n",
        "      gz_norm = jnp.linalg.norm(gz)\n",
        "      nstep += 1\n",
        "\n",
        "    z = z.reshape(*orig_shape).astype(jnp.float32)\n",
        "\n",
        "    # assert False\n",
        "\n",
        "    return z\n",
        "\n",
        "def direct_jax(f, z0, x0, threshold, eps=1e-3):\n",
        "    # TODO replace with jax while\n",
        "\n",
        "    nstep = 0\n",
        "    z_old = z0\n",
        "    z_new = f(z0,x0)\n",
        "    gz = z_new-z_old\n",
        "    gz_norm = jnp.linalg.norm(gz)\n",
        "    min_gz_norm, min_z = gz_norm, z_new\n",
        "    while nstep < threshold and gz_norm > eps:\n",
        "      z_old = z_new\n",
        "      z_new = f(z_old,x0)\n",
        "      gz = z_new-z_old\n",
        "      gz_norm = jnp.linalg.norm(gz)\n",
        "      if gz_norm < min_gz_norm:\n",
        "        min_gz_norm, min_z = gz_norm, z_new\n",
        "      nstep += 1\n",
        "    # print(\"min_gz_norm\",min_gz_norm,\"nstep\",nstep)\n",
        "    return min_z\n"
      ],
      "metadata": {
        "id": "JDts6pYBWEpv"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MDEQBlock(nn.Module):\n",
        "    curr_branch: int\n",
        "    channels: List[int]\n",
        "    kernel_size: Tuple[int] = (3, 3) \n",
        "    num_groups: int = 2\n",
        "    kernel_init = jax.nn.initializers.glorot_normal()\n",
        "    bias_init = jax.nn.initializers.glorot_normal()\n",
        "\n",
        "    \n",
        "    def setup(self):  \n",
        "        self.input_dim = self.channels[self.curr_branch]\n",
        "        self.hidden_dim = 2*self.input_dim\n",
        "\n",
        "        self.conv1 = nn.Conv(features=self.hidden_dim, kernel_size=self.kernel_size,\n",
        "                             strides=(1,1))\n",
        "        self.group1 = nn.GroupNorm(num_groups=self.num_groups)\n",
        "\n",
        "        self.relu = nn.relu\n",
        "        self.conv2 = nn.Conv(features=self.input_dim, kernel_size=self.kernel_size,\n",
        "                             strides=(1,1))\n",
        "        self.group2 = nn.GroupNorm(num_groups=self.num_groups)\n",
        "        self.group3 = nn.GroupNorm(num_groups=self.num_groups)\n",
        "\n",
        "\n",
        "    def __call__(self, x, branch, injection):\n",
        "        # forward pass\n",
        "        h1 = self.group1(self.conv1(x))\n",
        "        h1 = self.relu(h1)\n",
        "        h2 = self.conv2(h1)\n",
        "        \n",
        "        # inject original input if resolution=0 \n",
        "        if branch == 0:\n",
        "            h2 += injection\n",
        "        \n",
        "        h2 = self.group2(h2)\n",
        "        # residual\n",
        "        h2 += x\n",
        "        h3 = self.relu(h2)\n",
        "        out = self.group3(h3)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "EzcfTWz6agE_"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "    channels: List[int]\n",
        "    branches: Tuple[int]\n",
        "    num_groups: int\n",
        "    kernel_init = jax.nn.initializers.glorot_normal()\n",
        "\n",
        "    def setup(self):\n",
        "        self.in_chan = self.channels[self.branches[0]]\n",
        "        self.out_chan  = self.channels[self.branches[1]]\n",
        "        to_res, from_res = self.branches  # sampling from resolution from_res to to_res\n",
        "        \n",
        "        num_samples = to_res - from_res \n",
        "        assert num_samples > 0\n",
        "\n",
        "        down_block = []\n",
        "        conv_down = nn.Conv(features=self.in_chan, kernel_size=(3,3), strides=(2,2), padding=((1,1),(1,1)), use_bias=False)\n",
        "        group_down = nn.GroupNorm(num_groups=self.num_groups)\n",
        "        relu_down = nn.relu\n",
        "\n",
        "        for n in range(num_samples-1):\n",
        "            down_block += [conv_down, group_down, relu_down]\n",
        "        conv_down = nn.Conv(features=self.out_chan, kernel_size=(3,3), strides=(2,2), padding=((1,1),(1,1)), use_bias=False)\n",
        "        down_block += [conv_down, group_down]\n",
        "        self.downsample_fn = nn.Sequential(down_block)\n",
        "\n",
        "    def __call__(self, z_plus):\n",
        "        out = self.downsample_fn(z_plus)\n",
        "        return out"
      ],
      "metadata": {
        "id": "1fO-Bsnly9Jp"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "    channels: List[int]\n",
        "    branches: Tuple[int]\n",
        "    num_groups: int\n",
        "    kernel_init = jax.nn.initializers.glorot_normal()\n",
        "\n",
        "    \n",
        "    def setup(self):\n",
        "        self.in_chan = self.channels[self.branches[0]]\n",
        "        self.out_chan = self.channels[self.branches[1]]\n",
        "        self.upsample_fn = self._upsample()\n",
        "        \n",
        "    ''' the following is from https://github.com/google/jax/issues/862 '''\n",
        "    \n",
        "    def interpolate_bilinear(self, im, rows, cols):\n",
        "        # based on http://stackoverflow.com/a/12729229\n",
        "        col_lo = np.floor(cols).astype(int)\n",
        "        col_hi = col_lo + 1\n",
        "        row_lo = np.floor(rows).astype(int)\n",
        "        row_hi = row_lo + 1\n",
        "\n",
        "        nrows, ncols = im.shape[-3:-1]\n",
        "        def cclip(cols): return np.clip(cols, 0, ncols - 1)\n",
        "        def rclip(rows): return np.clip(rows, 0, nrows - 1)\n",
        "        Ia = im[..., rclip(row_lo), cclip(col_lo), :]\n",
        "        Ib = im[..., rclip(row_hi), cclip(col_lo), :]\n",
        "        Ic = im[..., rclip(row_lo), cclip(col_hi), :]\n",
        "        Id = im[..., rclip(row_hi), cclip(col_hi), :]\n",
        "\n",
        "        wa = np.expand_dims((col_hi - cols) * (row_hi - rows), -1)\n",
        "        wb = np.expand_dims((col_hi - cols) * (rows - row_lo), -1)\n",
        "        wc = np.expand_dims((cols - col_lo) * (row_hi - rows), -1)\n",
        "        wd = np.expand_dims((cols - col_lo) * (rows - row_lo), -1)\n",
        "\n",
        "        return wa*Ia + wb*Ib + wc*Ic + wd*Id\n",
        "\n",
        "    def upsampling_wrap(self, resize_rate):\n",
        "        def upsampling_method(img):\n",
        "            nrows, ncols = img.shape[-3:-1]\n",
        "            delta = 0.5/resize_rate\n",
        "\n",
        "            rows = np.linspace(delta,nrows-delta, np.int32(resize_rate*nrows))\n",
        "            cols = np.linspace(delta,ncols-delta, np.int32(resize_rate*ncols))\n",
        "            ROWS, COLS = np.meshgrid(rows,cols,indexing='ij')\n",
        "        \n",
        "            img_resize_vec = self.interpolate_bilinear(img, ROWS.flatten(), COLS.flatten())\n",
        "            img_resize =  img_resize_vec.reshape(img.shape[:-3] + \n",
        "                                                (len(rows),len(cols)) + \n",
        "                                                img.shape[-1:])\n",
        "        \n",
        "            return img_resize\n",
        "        return upsampling_method\n",
        "    ''' end copy '''\n",
        "\n",
        "\n",
        "    def _upsample(self):\n",
        "        to_res, from_res = self.branches  # sampling from resolution from_res to to_res\n",
        "        num_samples = from_res - to_res \n",
        "        assert num_samples > 0\n",
        "\n",
        "        return nn.Sequential([nn.Conv(features=self.out_chan, kernel_size=(1, 1), use_bias=False), #kernel_init=self.kernel_init),\n",
        "                        nn.GroupNorm(num_groups=self.num_groups),\n",
        "                        self.upsampling_wrap(resize_rate=2**num_samples)])\n",
        "\n",
        "    def __call__(self, z_plus):\n",
        "        return self.upsample_fn(z_plus)"
      ],
      "metadata": {
        "id": "pApLGNTRK8OW"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cringy_reshape(in_vec, shape_list):\n",
        "    start = 0\n",
        "    out_vec = []\n",
        "    if isinstance(in_vec, list):\n",
        "        raise ValueError\n",
        "    # in_vec = jnp.array(in_vec)\n",
        "    for size in shape_list:\n",
        "        my_elems = jnp.prod(jnp.array(size[1:]))\n",
        "        end = start+my_elems\n",
        "        my_chunk = jnp.copy(in_vec[:, start:end])\n",
        "        start += my_elems\n",
        "        my_chunk = jnp.reshape(my_chunk, size)\n",
        "        out_vec.append(my_chunk)\n",
        "\n",
        "    return out_vec\n",
        "        "
      ],
      "metadata": {
        "id": "LMLCzlwHO3A0"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Maps image to initial latent representation\n",
        "    AKA the grey part in the diagram\n",
        "    \"\"\"\n",
        "\n",
        "    channels: List[int] = field(default_factory=lambda:[24, 24])\n",
        "    training: bool = True\n",
        "\n",
        "    def setup(self):\n",
        "        self.conv1 = nn.Conv(features=self.channels[0], \n",
        "                             kernel_size=(3, 3), strides=(1, 1))\n",
        "        self.bn1 = nn.BatchNorm()\n",
        "        self.relu = nn.relu\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x), use_running_average=True))\n",
        "        return x"
      ],
      "metadata": {
        "id": "ozN6cMheafUj"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CLSBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A tool for using the \n",
        "    \"\"\"\n",
        "    input_dim: int\n",
        "    output_dim: int\n",
        "    downsample: bool\n",
        "    expansion: int=4\n",
        "    \n",
        "    def setup(self):  \n",
        "\n",
        "        # init-substitute for flax\n",
        "        self.conv1 = nn.Conv(features=self.output_dim, kernel_size=(1,1),\n",
        "                             strides=(1,1))#, kernel_init=self.kernel_init, bias_init=self.bias_init)\n",
        "        self.bn1 = nn.BatchNorm()\n",
        "        self.relu = nn.relu\n",
        "        self.conv2 = nn.Conv(features=self.output_dim, kernel_size=(3,3), strides=(1,1))#, kernel_init=self.kernel_init, bias_init=self.bias_init)\n",
        "        self.bn2 = nn.BatchNorm()\n",
        "        self.conv3 = nn.Conv(features=self.output_dim*self.expansion, kernel_size=(1,1), strides=(1,1))#, kernel_init=self.kernel_init, bias_init=self.bias_init)\n",
        "        self.bn3 = nn.BatchNorm()\n",
        "\n",
        "        if self.downsample:\n",
        "            self.ds_conv = nn.Conv(self.output_dim*self.expansion, kernel_size=(1,1), strides=(1,1), use_bias=False)\n",
        "            self.ds_bn = nn.BatchNorm()\n",
        "\n",
        "\n",
        "    def __call__(self, x, injection=None):\n",
        "        # forward pass\n",
        "        if injection is None:\n",
        "          injection = 0\n",
        "        h1 = self.bn1(self.conv1(x), use_running_average=True)\n",
        "        h1 = self.relu(h1)\n",
        "        h2 = self.bn2(self.conv2(h1), use_running_average=True)\n",
        "        h2 = self.relu(h2)\n",
        "        h3 = self.bn3(self.conv3(h2), use_running_average=True)\n",
        "        if self.downsample:\n",
        "          x = self.ds_bn(self.ds_conv(x), use_running_average=True)\n",
        "        h3 += x\n",
        "        return nn.relu(h3)"
      ],
      "metadata": {
        "id": "NeXb7CTi-Imp"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "DAYfgxMOGUNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    channels: List[int] = field(default_factory=lambda:[24, 24])\n",
        "    output_channels: List[int] = field(default_factory=lambda:[8, 16])\n",
        "    expansion: int = 4\n",
        "    final_chansize: int = 200\n",
        "    num_classes: int = 10\n",
        "\n",
        "    def make_cls_block(self, in_chan, out_chan):\n",
        "          downsample = False\n",
        "          if in_chan != out_chan * self.expansion:\n",
        "              downsample = True\n",
        "          return CLSBlock(in_chan, out_chan, downsample)\n",
        "\n",
        "    def setup(self):\n",
        "        self.num_branches = len(self.channels)\n",
        "\n",
        "        combine_modules = []\n",
        "        for i  in range(len(self.channels)):\n",
        "            output_mod = self.make_cls_block(self.channels[i], self.output_channels[i])\n",
        "            combine_modules.append(output_mod)\n",
        "        self.combine_modules = combine_modules\n",
        "\n",
        "        self.final_layer_conv = nn.Conv(self.final_chansize, kernel_size=(1,1))\n",
        "        self.final_layer_bn = nn.BatchNorm()\n",
        "\n",
        "        self.classifier = nn.Dense(self.num_classes)\n",
        "                                         \n",
        "    def __call__(self, y):\n",
        "        y_final = self.combine_modules[0](y[0])\n",
        "        for i in range(len(self.channels)-1):\n",
        "            y_final = self.combine_modules[i+1](y[i+1]) \n",
        "        y_final = self.final_layer_bn(self.final_layer_conv(y_final), use_running_average=True)\n",
        "        y_final = nn.relu(y_final)\n",
        "        y_final = nn.avg_pool(y_final, window_shape=y_final.shape[1:3])\n",
        "        y_final = jnp.reshape(y_final, (y_final.shape[0], -1))\n",
        "        y_final = self.classifier(y_final)\n",
        "        return y_final"
      ],
      "metadata": {
        "id": "REW0m6Hf1tvv"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(image, label, num_classes=10):\n",
        "    image = jnp.float32(image) / 255.\n",
        "    image = np.expand_dims(image, -1)\n",
        "    # image = np.tile(image, (1,1,1,24))\n",
        "    label = jnp.array(label)\n",
        "    return image, label\n",
        "\n",
        "def load_data():\n",
        "    test_ds = torchvision.datasets.MNIST(root=\"data\", train=False,download=True)\n",
        "    train_ds = torchvision.datasets.MNIST(root=\"data\", train=True,download=True)\n",
        "\n",
        "    train_images, train_labels = transform(train_ds.data[:1000], train_ds.targets[:1000])\n",
        "    test_images, test_labels = transform(test_ds.data[:100], test_ds.targets[:100])\n",
        "    print(f\"MUM TRAINING IMAGES:::{train_images.shape[0]}\")\n",
        "    print(f\"MUM TEST IMAGES:::{test_images.shape[0]}\")\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n"
      ],
      "metadata": {
        "id": "qCtrgYH-K2b8"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jax.custom_vjp, nondiff_argnums=(0, 1, 2, 3,)) # nondiff are all except for weights and z/x\n",
        "def rootfind(solver_fn: Callable,\n",
        "                 f_fn: Callable,\n",
        "                 threshold: int,\n",
        "                 eps: float,\n",
        "                 weights: dict,\n",
        "                 z: jnp.ndarray,\n",
        "                 x: jnp.ndarray):\n",
        "    f_fn = partial(f_fn, weights)\n",
        "    return jax.lax.stop_gradient(solver_fn(f_fn, z, x, threshold, eps=1e-3))\n",
        "\n",
        "# Its forward call (basically just calling it)\n",
        "def _rootfind_fwd(solver_fn: Callable,\n",
        "                      f_fn: Callable,\n",
        "                      threshold: int,\n",
        "                      eps: float,\n",
        "                      weights: dict,\n",
        "                      z: jnp.ndarray,\n",
        "                      x: jnp.ndarray):\n",
        "    z = rootfind(solver_fn, f_fn, threshold, eps, weights, z, x)\n",
        "    # print(\"fwd residual\",jnp.linalg.norm(f_fn(weights,z,x)-z)/jnp.linalg.norm(z))\n",
        "    return z, (weights, z, x)\n",
        "\n",
        "# Its backward call (its inputs)\n",
        "def _rootfind_bwd(solver_fn: Callable,\n",
        "                      f_fn: Callable,\n",
        "                      threshold: int,\n",
        "                      eps: float,\n",
        "                      res,  \n",
        "                      grad):\n",
        "    weights, z, x = res\n",
        "    (_, vjp_fun) = jax.vjp(f_fn, weights, z, x)\n",
        "    def z_fn(z,x): # gets transpose Jac w.r.t. weights and z using vjp_fun\n",
        "        (Jw_T, Jz_T, _) = vjp_fun(z)\n",
        "        return Jz_T + grad\n",
        "    #def gimme_jzt(z):\n",
        "     #   (Jw_T, Jz_T, _) = vjp_fun(z)\n",
        "      #  return Jz_T\n",
        "\n",
        "    #z0 = jnp.zeros_like(grad)\n",
        "    key, subkey = random.split(jax.random.PRNGKey(0))\n",
        "    z0 = random.normal(subkey, grad.shape)\n",
        "    x0 = None # dummy, z_fn does not use x\n",
        "    g = solver_fn(z_fn, z0, x0, threshold, eps)\n",
        "    #Jz_T = gimme_jzt(z0)\n",
        "    #g = -jnp.transpose(jnp.linalg.pinv(Jz_T) * jnp.transpose(grad))\n",
        "    #print('diff broyden vs inv', jnp.linalg.norm(g - g_p))\n",
        "    #print(\"bwd residual\",jnp.linalg.norm(z_fn(g,x0)-g)/jnp.linalg.norm(g))\n",
        "    return (None, g, None)\n",
        "\n",
        "rootfind.defvjp(_rootfind_fwd, _rootfind_bwd)"
      ],
      "metadata": {
        "id": "q61ohtb5HKwj"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MDEQFF(nn.Module):\n",
        "    \"\"\"\n",
        "    The f_{\\theta}(z,x) function that is repeatedly applied\n",
        "    AKA the yellow block in the diagram\n",
        "    \"\"\"\n",
        "    num_branches: int\n",
        "    channels: List[int]\n",
        "    num_groups: int\n",
        "    kernel_init = jax.nn.initializers.glorot_normal()\n",
        "   \n",
        "    def setup(self):\n",
        "\n",
        "        self.branches = self.stack_branches()\n",
        "        self.fuse_branches = self.fuse()\n",
        "        self.transform = self.transform_output()\n",
        "\n",
        "    def stack_branches(self):\n",
        "        branches = []\n",
        "        for i in range(self.num_branches):\n",
        "          branches.append(MDEQBlock(curr_branch=i, channels=self.channels))\n",
        "        return branches\n",
        "\n",
        "    def fuse(self):#, z_plus, channel_dimensions):\n",
        "        # up- and downsampling stuff\n",
        "        # z_plus: output of residual block\n",
        "        if self.num_branches == 1:\n",
        "            return None\n",
        "        \n",
        "        fuse_layers = []\n",
        "        for i in range(self.num_branches):\n",
        "            array = []\n",
        "            for j in range(self.num_branches):\n",
        "                if i == j:\n",
        "                    array.append(None)\n",
        "                else:\n",
        "                    if i > j:\n",
        "                        sampled = DownSample(branches=(i, j), channels=self.channels, num_groups=self.num_groups)\n",
        "                    elif i < j:\n",
        "                        sampled = UpSample(branches=(i, j), channels=self.channels, num_groups=self.num_groups)\n",
        "                    array.append(sampled)\n",
        "            fuse_layers.append(array)\n",
        "\n",
        "        return fuse_layers\n",
        "    \n",
        "    def transform_output(self):\n",
        "        transforms = []\n",
        "        for i in range(self.num_branches):\n",
        "          transforms.append(nn.Sequential([nn.Conv(features=self.channels[i], kernel_size=(1, 1),\n",
        "                                                  use_bias=False),\n",
        "                                           nn.relu,\n",
        "                                           nn.GroupNorm(num_groups=self.num_groups)]))\n",
        "        \n",
        "        return transforms\n",
        "\n",
        "    def __call__(self, z, x, shape_tuple):\n",
        "        \n",
        "        batch_size = z.shape[0]\n",
        "        z_list = cringy_reshape(z,shape_tuple)\n",
        "        x_list = cringy_reshape(x,shape_tuple)\n",
        "        # step 1: compute residual blocks\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_branches):\n",
        "            branch_outputs.append(self.branches[i](z_list[i], i, x_list[i])) # z, branch, x\n",
        "        # step 2: fuse residual blocks\n",
        "        fuse_outputs = []\n",
        "        for i in range(self.num_branches):\n",
        "            intermediate_i = jnp.zeros(branch_outputs[i].shape) \n",
        "            for j in range(self.num_branches):\n",
        "                if i == j:\n",
        "                  intermediate_i += branch_outputs[j]\n",
        "                else:\n",
        "                    if self.fuse_branches[i][j] is not None:\n",
        "                        temp = self.fuse_branches[i][j](z_plus=branch_outputs[j])#, branches=(i, j))\n",
        "                        intermediate_i += temp\n",
        "                    else:\n",
        "                        raise Exception(\"Should not happen.\")\n",
        "            fuse_outputs.append(self.transform[i](intermediate_i))\n",
        "          # stick z back into into one vector\n",
        "        fuse_outputs = jnp.concatenate([fo.reshape(batch_size,-1) for fo in fuse_outputs],axis=1)\n",
        "        assert fuse_outputs.shape[1] == z.shape[1]\n",
        "        return fuse_outputs\n"
      ],
      "metadata": {
        "id": "dWkUS52WoaiC"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mdeq_inputs(x,num_branches):\n",
        "\n",
        "  batch_size = x.shape[0]\n",
        "  x_list = [x]\n",
        "  for i in range(1, num_branches):\n",
        "      bs, H, W, y = x_list[-1].shape\n",
        "      new_item = jnp.zeros((bs, H//2, W//2, y))\n",
        "      x_list.append(new_item)\n",
        "  z_list = [jnp.zeros_like(elem) for elem in x_list]\n",
        "  shape_list = [el.shape for el in z_list]\n",
        "  # make them (batched) vectors\n",
        "  x_vec = jnp.concatenate([x.reshape(batch_size,-1) for x in x_list],axis=1)\n",
        "  z_vec = jnp.concatenate([z.reshape(batch_size,-1) for z in z_list],axis=1)\n",
        "  # i'm not sure if tuple is actually important but I like it for non-mutability\n",
        "  shape_tuple = tuple(shape_list)\n",
        "  return x_vec, z_vec, shape_tuple\n",
        "\n",
        "\n",
        "def mdeq_fn(x,encoder,decoder,deqff,all_weights,solver_fn=None,mode='broyden'):\n",
        "    threshold = 7\n",
        "    eps = 1e-3\n",
        "    encoder_weights = all_weights[\"encoder\"]\n",
        "    decoder_weights = all_weights[\"decoder\"]\n",
        "    deqff_weights = all_weights[\"mdeqff\"]\n",
        "    batch_size = x.shape[0]\n",
        "    # transform the input image\n",
        "    x = encoder.apply(encoder_weights,x)\n",
        "    # construct inputs (lots of padding and concatenation)\n",
        "    x, z, shape_tuple = create_mdeq_inputs(x,deqff.num_branches)\n",
        "    if mode == 'broyden':\n",
        "      # the root function can only take 3 ndarrays as input\n",
        "      def deqff_root(_weights,_z,_x):\n",
        "        # note: it's safe to pass the shape_tuple here (no tracers)\n",
        "        return deqff.apply(_weights,_z,_x,shape_tuple)\n",
        "      # apply rootfinder with custom vjp\n",
        "      z = rootfind(solver_fn,deqff_root,threshold,eps,deqff_weights,z,x)\n",
        "  \n",
        "    elif mode == \"direct_solver\":\n",
        "        max_evals = 5\n",
        "        threshold=1e-2\n",
        "        evals = 0\n",
        "        residual = jnp.inf\n",
        "        while evals < max_evals and residual > threshold:\n",
        "          z = deqff.apply(deqff_weights,z,x,shape_tuple)\n",
        "          f_z = deqff.apply(deqff_weights,z,x,shape_tuple)\n",
        "          residual = jnp.linalg.norm(f_z - z) / jnp.linalg.norm(z)\n",
        "          evals += 1\n",
        "      \n",
        "    elif mode in [\"predict\", \"warmup\"]:\n",
        "      z = deqff.apply(deqff_weights,z,x,shape_tuple)\n",
        "\n",
        "    z_list = cringy_reshape(z,shape_tuple)\n",
        "    log_probs = decoder.apply(decoder_weights,z_list)\n",
        "\n",
        "    f_z = deqff.apply(deqff_weights,z,x,shape_tuple)\n",
        "    residuals = jnp.linalg.norm(f_z - z) / jnp.linalg.norm(z)\n",
        "    # reshape back to list\n",
        "    \n",
        "    return log_probs, residuals"
      ],
      "metadata": {
        "id": "5hI7s8DE1kqX"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def cross_entropy_loss(logits, labels):\n",
        "    ''' \n",
        "    should be same as  optax.softmax_cross_entropy(logits, labels); \n",
        "    if getting funny results maybe remove log of logits\n",
        "    '''\n",
        "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
        "    logits = jax.nn.log_softmax(logits)\n",
        "    acc = (jnp.argmax(logits, axis=-1) == labels).mean()\n",
        "    output = -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))\n",
        "    return output, acc"
      ],
      "metadata": {
        "id": "r8M7Sf_gmqD7"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(images,labels,encoder,decoder,deqff,all_weights):\n",
        "    loss, acc = 0,0\n",
        "    batch_size = 128\n",
        "    start, end = 0, 0\n",
        "    loss_vals = []\n",
        "    acc_vals = []\n",
        "    while end < images.shape[0]:\n",
        "        end = min(start+batch_size, images.shape[0])\n",
        "        x_batch = images[start:end]\n",
        "        x_batch = jnp.tile(x_batch, (1,1,1,24))\n",
        "\n",
        "        y_true = labels[start:end]\n",
        "        start = end\n",
        "\n",
        "        log_probs, residual = mdeq_fn(x_batch,encoder,decoder,deqff,all_weights,mode='predict')\n",
        "        loss, acc = cross_entropy_loss(log_probs, y_true)\n",
        "        loss_vals.append(loss * x_batch.shape[0])\n",
        "        acc_vals.append(acc * x_batch.shape[0])\n",
        "    return sum(jnp.array(loss_vals)) / images.shape[0], sum(jnp.array(acc_vals)) / images.shape[0], residual"
      ],
      "metadata": {
        "id": "1kUlVk4z0LOV"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(mode=\"broyden\"):\n",
        "\n",
        "    assert mode in [\"broyden\", \"direct_solver\", \"warmup\"], \"INCORRECT MODE\"\n",
        "\n",
        "    train_images, train_labels, test_images, test_labels = load_data()\n",
        "    num_images = train_images.shape[0]\n",
        "    image_size = train_images.shape[1]\n",
        "    batch_size = 128\n",
        "    assert batch_size <= train_images.shape[0]\n",
        "\n",
        "    solver_fn = direct_jax\n",
        "\n",
        "    num_groups = 8\n",
        "    channels = [24, 24]\n",
        "    num_branches = 2\n",
        "\n",
        "    # instantiation\n",
        "    encoder = Encoder(channels=channels)\n",
        "    decoder = Classifier() # not sure about what to pass\n",
        "    mdeqff = MDEQFF(num_branches=num_branches, channels=channels, num_groups=num_groups)\n",
        "\n",
        "    # weight initialization\n",
        "    prng = jax.random.PRNGKey(0)\n",
        "    prng, _ = jax.random.split(prng, 2)\n",
        "    x_dummy = jnp.ones((batch_size, image_size, image_size, 24))\n",
        "    x_dummy_2, encoder_weights = encoder.init_with_output(prng,x_dummy)\n",
        "    x_dummy_3, z_dummy, shape_tuple = create_mdeq_inputs(x_dummy_2,num_branches)\n",
        "    z_dummy_2, mdeqff_weights = mdeqff.init_with_output(prng,z_dummy,x_dummy_3,shape_tuple)\n",
        "    z_dummy_3 = cringy_reshape(z_dummy_2,shape_tuple)\n",
        "    o_dummy, classifier_weights = decoder.init_with_output(prng,z_dummy_3)\n",
        "\n",
        "    # collect weights\n",
        "    weights = {'encoder': encoder_weights, 'mdeqff': mdeqff_weights ,'decoder': classifier_weights}\n",
        "\n",
        "    optimizer = optax.adam(learning_rate=0.001)\n",
        "    opt_state = optimizer.init(weights)\n",
        "\n",
        "    loss_fn = cross_entropy_loss\n",
        "\n",
        "    def loss(weights, x_batch, y_true, mode):\n",
        "        logits, residual = mdeq_fn(x_batch,encoder,decoder,mdeqff,weights,solver_fn,mode)\n",
        "        loss, acc = loss_fn(logits, y_true)\n",
        "        return loss, (acc, residual)\n",
        "\n",
        "    def step(weights, opt_state, x_batch, y_true, mode):\n",
        "        (loss_vals, (acc, residual)), grad = jax.value_and_grad(loss, has_aux=True)(weights, x_batch, y_true, mode)\n",
        "        updates, opt_state = optimizer.update(grad, opt_state, weights)\n",
        "        weights = optax.apply_updates(weights, updates)\n",
        "\n",
        "        return weights, opt_state, loss_vals, acc, residual\n",
        "\n",
        "    def generator(batch_size: int=10):\n",
        "        ''' https://optax.readthedocs.io/en/latest/meta_learning.html?highlight=generator#meta-learning '''\n",
        "        rng = jax.random.PRNGKey(0)\n",
        "\n",
        "        while True:\n",
        "            rng, k1 = jax.random.split(rng, num=2)\n",
        "            idxs = jax.random.randint(k1, shape=(batch_size,), minval=0, maxval=num_images, dtype=jnp.int32)\n",
        "            yield idxs\n",
        "\n",
        "    def list_shuffler(seed):\n",
        "        rng = jax.random.PRNGKey(seed)\n",
        "        rng, k1 = jax.random.split(rng, num=2)\n",
        "        indices = jnp.arange(0, train_images.shape[0])\n",
        "        shuffled_indices = jax.random.shuffle(k1, indices)\n",
        "        return shuffled_indices\n",
        "    \n",
        "    max_epoch = 50\n",
        "    warmup_epochs = 0\n",
        "    if mode == \"warmup\":\n",
        "      warmup_epochs = 2\n",
        "      max_epoch += warmup_epochs\n",
        "    print_interval = 1\n",
        "\n",
        "    train_log, val_log = [],[]\n",
        "    if mode == \"warmup\":\n",
        "        print(f\"TRAINING MODE:::{mode}+broyden\")\n",
        "    else:\n",
        "        print(f\"TRAINING MODE:::{mode}\")\n",
        "    train_loss_vals, val_loss_vals = [], []\n",
        "    train_acc_vals, val_acc_vals = [], []\n",
        "    train_res_vals, val_res_vals = [], []\n",
        "\n",
        "    for epoch in range(max_epoch):\n",
        "        if mode == \"warmup\":\n",
        "          if epoch >= warmup_epochs:\n",
        "            mode = \"broyden\"\n",
        "            print(\"-------------DONE WARM UP---------------\")\n",
        "          elif epoch == 0:\n",
        "            print(\"----------STARTING WARM UP--------------\")\n",
        "            \n",
        "        idxs = list_shuffler(epoch)\n",
        "        start, end = 0, 0\n",
        "\n",
        "        loss_vals = []\n",
        "        acc_vals = []\n",
        "        res_vals = []\n",
        "\n",
        "        counter = 0\n",
        "        while end < len(idxs):\n",
        "            end = min(start+batch_size, len(idxs))\n",
        "            idxs_to_grab = idxs[start:end]\n",
        "            x_batch = train_images[idxs_to_grab,...]\n",
        "            x_batch = jnp.tile(x_batch, (1,1,1,24))\n",
        "            y_true = train_labels[idxs_to_grab]\n",
        "            start = end\n",
        "  \n",
        "            weights, opt_state, batch_loss, batch_acc, batch_res = step(weights=weights,\n",
        "                                                                        opt_state=opt_state,\n",
        "                                                                        x_batch=x_batch,\n",
        "                                                                        y_true=y_true,\n",
        "                                                                        mode=mode)\n",
        "            \n",
        "            counter += 1\n",
        "\n",
        "            loss_vals.append(batch_loss * x_batch.shape[0])\n",
        "            acc_vals.append(batch_acc * x_batch.shape[0])\n",
        "            res_vals.append(batch_res * x_batch.shape[0])\n",
        "\n",
        "\n",
        "            print(f\"batch_loss {counter} :: {batch_loss} // batch_acc :: {batch_acc} // batch_res :: {batch_res} \")\n",
        "\n",
        "        epoch_loss = sum(jnp.array(loss_vals)) / len(idxs)\n",
        "        epoch_acc = sum(jnp.array(acc_vals)) / len(idxs)\n",
        "        epoch_res = sum(jnp.array(res_vals)) / len(idxs)\n",
        "        \n",
        "        train_loss_vals.append(epoch_loss)\n",
        "        train_acc_vals.append(epoch_acc)\n",
        "        train_res_vals.append(epoch_res)\n",
        "\n",
        "        val_loss, val_acc, val_res = predict(test_images,test_labels,encoder,decoder,mdeqff,weights)\n",
        "\n",
        "        val_loss_vals.append(val_loss)\n",
        "        val_acc_vals.append(val_acc)\n",
        "        val_res_vals.append(val_res)\n",
        "\n",
        "        if epoch % print_interval == 0:\n",
        "            print(f\"\\tTRAIN epoch = {epoch} / loss = {epoch_loss} / acc = {epoch_acc} / res = {epoch_res}\")\n",
        "            print(f\"\\tVAL epoch = {epoch} / loss = {val_loss} / acc = {val_acc} / res = {val_res}\")\n",
        "\n",
        "        if epoch_loss < 1e-5:\n",
        "            break\n",
        "\n",
        "            print('finally', batch_loss)\n",
        "    results = {'train_loss_vals': train_loss_vals,\n",
        "               'train_acc_vals': train_acc_vals,\n",
        "               'train_res_vals': train_res_vals,\n",
        "               'val_loss_vals': val_loss_vals,\n",
        "               'val_acc_vals': val_acc_vals,\n",
        "               'val_res_vals': val_res_vals}\n",
        "    return results"
      ],
      "metadata": {
        "id": "S_3FNBfqojTY"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "broyden_results = train(mode=\"warmup\")"
      ],
      "metadata": {
        "id": "wNA8y6PdRdZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8460cd16-d5d9-4c2d-be46-1018646263e3"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MUM TRAINING IMAGES:::1000\n",
            "MUM TEST IMAGES:::100\n",
            "TRAINING MODE:::warmup+broyden\n",
            "----------STARTING WARM UP--------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/_src/random.py:371: FutureWarning: jax.random.shuffle is deprecated and will be removed in a future release. Use jax.random.permutation with independent=True.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_loss 1 :: 2.320387840270996 // batch_acc :: 0.1328125 // batch_res :: 1.1869990825653076 \n",
            "batch_loss 2 :: 2.3120193481445312 // batch_acc :: 0.1015625 // batch_res :: 1.2136832475662231 \n",
            "batch_loss 3 :: 2.319709062576294 // batch_acc :: 0.0859375 // batch_res :: 1.2027263641357422 \n",
            "batch_loss 4 :: 2.287677764892578 // batch_acc :: 0.078125 // batch_res :: 1.1976234912872314 \n",
            "batch_loss 5 :: 2.2948155403137207 // batch_acc :: 0.09375 // batch_res :: 1.1900830268859863 \n",
            "batch_loss 6 :: 2.3019089698791504 // batch_acc :: 0.1015625 // batch_res :: 1.1833769083023071 \n",
            "batch_loss 7 :: 2.304642915725708 // batch_acc :: 0.1015625 // batch_res :: 1.1673649549484253 \n",
            "batch_loss 8 :: 2.273872137069702 // batch_acc :: 0.11538462340831757 // batch_res :: 1.1604524850845337 \n",
            "\tTRAIN epoch = 0 / loss = 2.30255126953125 / acc = 0.10100000351667404 / res = 1.18844473361969\n",
            "\tVAL epoch = 0 / loss = 2.275960683822632 / acc = 0.14999999105930328 / res = 1.1530286073684692\n",
            "batch_loss 1 :: 2.2809183597564697 // batch_acc :: 0.09375 // batch_res :: 1.1566739082336426 \n",
            "batch_loss 2 :: 2.2732455730438232 // batch_acc :: 0.1875 // batch_res :: 1.163635015487671 \n",
            "batch_loss 3 :: 2.247633457183838 // batch_acc :: 0.2734375 // batch_res :: 1.1689014434814453 \n",
            "batch_loss 4 :: 2.2672317028045654 // batch_acc :: 0.203125 // batch_res :: 1.1849396228790283 \n",
            "batch_loss 5 :: 2.2571969032287598 // batch_acc :: 0.2265625 // batch_res :: 1.1926857233047485 \n",
            "batch_loss 6 :: 2.2371420860290527 // batch_acc :: 0.21875 // batch_res :: 1.1963756084442139 \n",
            "batch_loss 7 :: 2.2352705001831055 // batch_acc :: 0.234375 // batch_res :: 1.1999455690383911 \n",
            "batch_loss 8 :: 2.2579140663146973 // batch_acc :: 0.2211538553237915 // batch_res :: 1.2066730260849 \n",
            "\tTRAIN epoch = 1 / loss = 2.2570488452911377 / acc = 0.2070000171661377 / res = 1.183178186416626\n",
            "\tVAL epoch = 1 / loss = 2.2099881172180176 / acc = 0.28999999165534973 / res = 1.2038288116455078\n",
            "batch_loss 1 :: 2.216416358947754 // batch_acc :: 0.265625 // batch_res :: 1.2077271938323975 \n",
            "batch_loss 2 :: 2.24783992767334 // batch_acc :: 0.140625 // batch_res :: 1.2090672254562378 \n",
            "batch_loss 3 :: 2.1906940937042236 // batch_acc :: 0.2734375 // batch_res :: 1.2091290950775146 \n",
            "batch_loss 4 :: 2.1890738010406494 // batch_acc :: 0.28125 // batch_res :: 1.2097594738006592 \n",
            "batch_loss 5 :: 2.2037546634674072 // batch_acc :: 0.265625 // batch_res :: 1.2142448425292969 \n",
            "batch_loss 6 :: 2.167539596557617 // batch_acc :: 0.25 // batch_res :: 1.2172045707702637 \n",
            "batch_loss 7 :: 2.1468958854675293 // batch_acc :: 0.3203125 // batch_res :: 1.2168490886688232 \n",
            "batch_loss 8 :: 2.1403489112854004 // batch_acc :: 0.3365384638309479 // batch_res :: 1.2201480865478516 \n",
            "\tTRAIN epoch = 2 / loss = 2.1889595985412598 / acc = 0.26500001549720764 / res = 1.2128450870513916\n",
            "\tVAL epoch = 2 / loss = 2.10960054397583 / acc = 0.3499999940395355 / res = 1.216343879699707\n",
            "batch_loss 1 :: 2.14258074760437 // batch_acc :: 0.3125 // batch_res :: 1.2190500497817993 \n",
            "batch_loss 2 :: 2.1054251194000244 // batch_acc :: 0.3359375 // batch_res :: 1.216753602027893 \n",
            "batch_loss 3 :: 2.108478307723999 // batch_acc :: 0.3359375 // batch_res :: 1.2202849388122559 \n",
            "batch_loss 4 :: 2.0276689529418945 // batch_acc :: 0.3671875 // batch_res :: 1.203322172164917 \n",
            "batch_loss 5 :: 2.0539650917053223 // batch_acc :: 0.2734375 // batch_res :: 1.1888824701309204 \n",
            "batch_loss 6 :: 2.0176002979278564 // batch_acc :: 0.3515625 // batch_res :: 1.174057126045227 \n",
            "batch_loss 7 :: 2.031877040863037 // batch_acc :: 0.296875 // batch_res :: 1.1555354595184326 \n",
            "batch_loss 8 :: 2.0405538082122803 // batch_acc :: 0.19230769574642181 // batch_res :: 1.1586873531341553 \n",
            "\tTRAIN epoch = 3 / loss = 2.066629648208618 / acc = 0.3110000193119049 / res = 1.1928730010986328\n",
            "\tVAL epoch = 3 / loss = 1.9480478763580322 / acc = 0.29999998211860657 / res = 1.1378793716430664\n",
            "batch_loss 1 :: 1.9018893241882324 // batch_acc :: 0.3125 // batch_res :: 1.1414145231246948 \n",
            "batch_loss 2 :: 2.0010933876037598 // batch_acc :: 0.2109375 // batch_res :: 1.1260555982589722 \n",
            "batch_loss 3 :: 1.9580274820327759 // batch_acc :: 0.2578125 // batch_res :: 1.1279628276824951 \n",
            "batch_loss 4 :: 1.972109079360962 // batch_acc :: 0.1953125 // batch_res :: 1.1250470876693726 \n",
            "batch_loss 5 :: 1.8162648677825928 // batch_acc :: 0.34375 // batch_res :: 1.1197519302368164 \n",
            "batch_loss 6 :: 1.9602941274642944 // batch_acc :: 0.234375 // batch_res :: 1.1183234453201294 \n",
            "batch_loss 7 :: 1.8608474731445312 // batch_acc :: 0.28125 // batch_res :: 1.1239453554153442 \n",
            "batch_loss 8 :: 1.8422119617462158 // batch_acc :: 0.32692310214042664 // batch_res :: 1.1332405805587769 \n",
            "\tTRAIN epoch = 4 / loss = 1.9158174991607666 / acc = 0.26900002360343933 / res = 1.126817226409912\n",
            "\tVAL epoch = 4 / loss = 1.8393855094909668 / acc = 0.3199999928474426 / res = 1.15187406539917\n",
            "-------------DONE WARM UP---------------\n",
            "batch_loss 1 :: 2.310847759246826 // batch_acc :: 0.1015625 // batch_res :: 0.9066250324249268 \n",
            "batch_loss 2 :: 2.322539806365967 // batch_acc :: 0.1015625 // batch_res :: 0.9070339798927307 \n",
            "batch_loss 3 :: 2.3065953254699707 // batch_acc :: 0.0859375 // batch_res :: 0.9225599765777588 \n",
            "batch_loss 4 :: 2.3287079334259033 // batch_acc :: 0.0859375 // batch_res :: 0.9091206789016724 \n",
            "batch_loss 5 :: 2.3177530765533447 // batch_acc :: 0.15625 // batch_res :: 0.9104840159416199 \n",
            "batch_loss 6 :: 2.244166851043701 // batch_acc :: 0.1640625 // batch_res :: 0.9139357209205627 \n",
            "batch_loss 7 :: 2.2752017974853516 // batch_acc :: 0.1640625 // batch_res :: 0.9124958515167236 \n",
            "batch_loss 8 :: 2.2788772583007812 // batch_acc :: 0.18269231915473938 // batch_res :: 0.9144431352615356 \n",
            "\tTRAIN epoch = 5 / loss = 2.2985472679138184 / acc = 0.1290000081062317 / res = 0.9120307564735413\n",
            "\tVAL epoch = 5 / loss = 2.9986631870269775 / acc = 0.14000000059604645 / res = 1.214367389678955\n",
            "batch_loss 1 :: 2.273566722869873 // batch_acc :: 0.140625 // batch_res :: 0.9142355918884277 \n",
            "batch_loss 2 :: 2.288843870162964 // batch_acc :: 0.0859375 // batch_res :: 0.9112303853034973 \n",
            "batch_loss 3 :: 2.243643283843994 // batch_acc :: 0.2265625 // batch_res :: 0.9174671173095703 \n",
            "batch_loss 4 :: 2.274723768234253 // batch_acc :: 0.1328125 // batch_res :: 0.9211812019348145 \n",
            "batch_loss 5 :: 2.258812665939331 // batch_acc :: 0.203125 // batch_res :: 0.9163134098052979 \n",
            "batch_loss 6 :: 2.272519588470459 // batch_acc :: 0.1796875 // batch_res :: 0.9219217896461487 \n",
            "batch_loss 7 :: 2.290987968444824 // batch_acc :: 0.15625 // batch_res :: 0.9184415340423584 \n",
            "batch_loss 8 :: 2.3331825733184814 // batch_acc :: 0.10576923191547394 // batch_res :: 0.9174042344093323 \n",
            "\tTRAIN epoch = 6 / loss = 2.278247594833374 / acc = 0.1550000011920929 / res = 0.9172712564468384\n",
            "\tVAL epoch = 6 / loss = 3.4986064434051514 / acc = 0.14000000059604645 / res = 1.2231853008270264\n",
            "batch_loss 1 :: 2.2821264266967773 // batch_acc :: 0.09375 // batch_res :: 0.9228807091712952 \n",
            "batch_loss 2 :: 2.241960048675537 // batch_acc :: 0.1875 // batch_res :: 0.920466423034668 \n",
            "batch_loss 3 :: 2.2619965076446533 // batch_acc :: 0.1171875 // batch_res :: 0.9173411726951599 \n",
            "batch_loss 4 :: 2.2454261779785156 // batch_acc :: 0.1875 // batch_res :: 0.9160357713699341 \n",
            "batch_loss 5 :: 2.295501232147217 // batch_acc :: 0.109375 // batch_res :: 0.9193665385246277 \n",
            "batch_loss 6 :: 2.2704949378967285 // batch_acc :: 0.1953125 // batch_res :: 0.9086463451385498 \n",
            "batch_loss 7 :: 2.2652950286865234 // batch_acc :: 0.1640625 // batch_res :: 0.9120525121688843 \n",
            "batch_loss 8 :: 2.2390859127044678 // batch_acc :: 0.23076924681663513 // batch_res :: 0.9122627377510071 \n",
            "\tTRAIN epoch = 7 / loss = 2.263303518295288 / acc = 0.15900000929832458 / res = 0.9162244200706482\n",
            "\tVAL epoch = 7 / loss = 3.578342914581299 / acc = 0.14000000059604645 / res = 1.2251403331756592\n",
            "batch_loss 1 :: 2.2575736045837402 // batch_acc :: 0.2265625 // batch_res :: 0.9158149361610413 \n",
            "batch_loss 2 :: 2.254356622695923 // batch_acc :: 0.2265625 // batch_res :: 0.9161816239356995 \n",
            "batch_loss 3 :: 2.2498726844787598 // batch_acc :: 0.1875 // batch_res :: 0.9157459735870361 \n",
            "batch_loss 4 :: 2.2382874488830566 // batch_acc :: 0.2265625 // batch_res :: 0.9179106950759888 \n",
            "batch_loss 5 :: 2.2159807682037354 // batch_acc :: 0.234375 // batch_res :: 0.9161636829376221 \n",
            "batch_loss 6 :: 2.2438888549804688 // batch_acc :: 0.2265625 // batch_res :: 0.9059002995491028 \n",
            "batch_loss 7 :: 2.252284526824951 // batch_acc :: 0.2265625 // batch_res :: 0.9177836775779724 \n",
            "batch_loss 8 :: 2.2373476028442383 // batch_acc :: 0.2211538553237915 // batch_res :: 0.9125832319259644 \n",
            "\tTRAIN epoch = 8 / loss = 2.24385142326355 / acc = 0.22200001776218414 / res = 0.9148128032684326\n",
            "\tVAL epoch = 8 / loss = 3.8681230545043945 / acc = 0.14000000059604645 / res = 1.2257754802703857\n",
            "batch_loss 1 :: 2.2197580337524414 // batch_acc :: 0.203125 // batch_res :: 0.9122613668441772 \n",
            "batch_loss 2 :: 2.241386890411377 // batch_acc :: 0.1796875 // batch_res :: 0.916713535785675 \n",
            "batch_loss 3 :: 2.2127292156219482 // batch_acc :: 0.265625 // batch_res :: 0.9152376651763916 \n",
            "batch_loss 4 :: 2.204627752304077 // batch_acc :: 0.2109375 // batch_res :: 0.9148666858673096 \n",
            "batch_loss 5 :: 2.206787109375 // batch_acc :: 0.2578125 // batch_res :: 0.9146643280982971 \n",
            "batch_loss 6 :: 2.2522099018096924 // batch_acc :: 0.1796875 // batch_res :: 0.9163004159927368 \n",
            "batch_loss 7 :: 2.2094125747680664 // batch_acc :: 0.203125 // batch_res :: 0.9094066619873047 \n",
            "batch_loss 8 :: 2.237308979034424 // batch_acc :: 0.18269231915473938 // batch_res :: 0.9123845100402832 \n",
            "\tTRAIN epoch = 9 / loss = 2.222684860229492 / acc = 0.2110000103712082 / res = 0.9140177369117737\n",
            "\tVAL epoch = 9 / loss = 4.057247161865234 / acc = 0.14000000059604645 / res = 1.2260169982910156\n",
            "batch_loss 1 :: 2.19765567779541 // batch_acc :: 0.2421875 // batch_res :: 0.9123031497001648 \n",
            "batch_loss 2 :: 2.2106471061706543 // batch_acc :: 0.21875 // batch_res :: 0.9144551157951355 \n",
            "batch_loss 3 :: 2.2259435653686523 // batch_acc :: 0.1953125 // batch_res :: 0.9144154787063599 \n",
            "batch_loss 4 :: 2.20217227935791 // batch_acc :: 0.25 // batch_res :: 0.9123077988624573 \n",
            "batch_loss 5 :: 2.1918864250183105 // batch_acc :: 0.3125 // batch_res :: 0.9166918992996216 \n",
            "batch_loss 6 :: 2.2210679054260254 // batch_acc :: 0.25 // batch_res :: 0.911705732345581 \n",
            "batch_loss 7 :: 2.200840950012207 // batch_acc :: 0.28125 // batch_res :: 0.9107955098152161 \n",
            "batch_loss 8 :: 2.1776490211486816 // batch_acc :: 0.23076924681663513 // batch_res :: 0.9171615839004517 \n",
            "\tTRAIN epoch = 10 / loss = 2.2041029930114746 / acc = 0.24800001084804535 / res = 0.9136472344398499\n",
            "\tVAL epoch = 10 / loss = 4.250261306762695 / acc = 0.14000000059604645 / res = 1.2261179685592651\n",
            "batch_loss 1 :: 2.156714916229248 // batch_acc :: 0.25 // batch_res :: 0.9152424931526184 \n",
            "batch_loss 2 :: 2.206480026245117 // batch_acc :: 0.1953125 // batch_res :: 0.9125834703445435 \n",
            "batch_loss 3 :: 2.1765224933624268 // batch_acc :: 0.171875 // batch_res :: 0.9092826843261719 \n",
            "batch_loss 4 :: 2.184685707092285 // batch_acc :: 0.25 // batch_res :: 0.9156569838523865 \n",
            "batch_loss 5 :: 2.1853020191192627 // batch_acc :: 0.3203125 // batch_res :: 0.9122559428215027 \n",
            "batch_loss 6 :: 2.176457405090332 // batch_acc :: 0.1796875 // batch_res :: 0.9134257435798645 \n",
            "batch_loss 7 :: 2.1964876651763916 // batch_acc :: 0.203125 // batch_res :: 0.9141601920127869 \n",
            "batch_loss 8 :: 2.177772045135498 // batch_acc :: 0.29807692766189575 // batch_res :: 0.9155657887458801 \n",
            "\tTRAIN epoch = 11 / loss = 2.1826674938201904 / acc = 0.23200000822544098 / res = 0.9134727120399475\n",
            "\tVAL epoch = 11 / loss = 4.480179786682129 / acc = 0.14000000059604645 / res = 1.2261617183685303\n",
            "batch_loss 1 :: 2.1861226558685303 // batch_acc :: 0.2109375 // batch_res :: 0.9112144112586975 \n",
            "batch_loss 2 :: 2.141214370727539 // batch_acc :: 0.21875 // batch_res :: 0.9146600365638733 \n",
            "batch_loss 3 :: 2.1375694274902344 // batch_acc :: 0.171875 // batch_res :: 0.9136287569999695 \n",
            "batch_loss 4 :: 2.1606483459472656 // batch_acc :: 0.1796875 // batch_res :: 0.9090229868888855 \n",
            "batch_loss 5 :: 2.1673688888549805 // batch_acc :: 0.2109375 // batch_res :: 0.914200484752655 \n",
            "batch_loss 6 :: 2.0905802249908447 // batch_acc :: 0.2890625 // batch_res :: 0.9146217107772827 \n",
            "batch_loss 7 :: 2.1727917194366455 // batch_acc :: 0.21875 // batch_res :: 0.9159091114997864 \n",
            "batch_loss 8 :: 2.1313998699188232 // batch_acc :: 0.3076923191547394 // batch_res :: 0.9139919281005859 \n",
            "\tTRAIN epoch = 12 / loss = 2.148871421813965 / acc = 0.2240000069141388 / res = 0.913392186164856\n",
            "\tVAL epoch = 12 / loss = 4.887156963348389 / acc = 0.14000000059604645 / res = 1.2261810302734375\n",
            "batch_loss 1 :: 2.12508225440979 // batch_acc :: 0.2578125 // batch_res :: 0.9111652374267578 \n",
            "batch_loss 2 :: 2.097149133682251 // batch_acc :: 0.2578125 // batch_res :: 0.9129260778427124 \n",
            "batch_loss 3 :: 2.1520912647247314 // batch_acc :: 0.2109375 // batch_res :: 0.9230008125305176 \n",
            "batch_loss 4 :: 2.167294502258301 // batch_acc :: 0.25 // batch_res :: 0.9114080667495728 \n",
            "batch_loss 5 :: 2.1484763622283936 // batch_acc :: 0.203125 // batch_res :: 0.9123333692550659 \n",
            "batch_loss 6 :: 2.090343952178955 // batch_acc :: 0.3125 // batch_res :: 0.9101436138153076 \n",
            "batch_loss 7 :: 2.066315174102783 // batch_acc :: 0.3125 // batch_res :: 0.9097556471824646 \n",
            "batch_loss 8 :: 2.1040682792663574 // batch_acc :: 0.25 // batch_res :: 0.9166863560676575 \n",
            "\tTRAIN epoch = 13 / loss = 2.1192073822021484 / acc = 0.25699999928474426 / res = 0.9133492112159729\n",
            "\tVAL epoch = 13 / loss = 5.364661693572998 / acc = 0.14000000059604645 / res = 1.2261897325515747\n",
            "batch_loss 1 :: 2.04794979095459 // batch_acc :: 0.21875 // batch_res :: 0.9153085350990295 \n",
            "batch_loss 2 :: 2.095261573791504 // batch_acc :: 0.2109375 // batch_res :: 0.9197071194648743 \n",
            "batch_loss 3 :: 2.0472564697265625 // batch_acc :: 0.3046875 // batch_res :: 0.9139142632484436 \n",
            "batch_loss 4 :: 2.040320634841919 // batch_acc :: 0.265625 // batch_res :: 0.9077329635620117 \n",
            "batch_loss 5 :: 2.1718013286590576 // batch_acc :: 0.1875 // batch_res :: 0.9108037352561951 \n",
            "batch_loss 6 :: 2.142181634902954 // batch_acc :: 0.1875 // batch_res :: 0.9106365442276001 \n",
            "batch_loss 7 :: 2.0948543548583984 // batch_acc :: 0.28125 // batch_res :: 0.9094353318214417 \n",
            "batch_loss 8 :: 2.035292863845825 // batch_acc :: 0.2788461744785309 // batch_res :: 0.9204460978507996 \n",
            "\tTRAIN epoch = 14 / loss = 2.085542678833008 / acc = 0.2410000115633011 / res = 0.9133313298225403\n",
            "\tVAL epoch = 14 / loss = 5.38880729675293 / acc = 0.14000000059604645 / res = 1.2261935472488403\n",
            "batch_loss 1 :: 2.038018226623535 // batch_acc :: 0.375 // batch_res :: 0.9126748442649841 \n",
            "batch_loss 2 :: 2.1127052307128906 // batch_acc :: 0.265625 // batch_res :: 0.9145520925521851 \n",
            "batch_loss 3 :: 2.052544593811035 // batch_acc :: 0.265625 // batch_res :: 0.9138581156730652 \n",
            "batch_loss 4 :: 1.9872462749481201 // batch_acc :: 0.2890625 // batch_res :: 0.9158234000205994 \n",
            "batch_loss 5 :: 2.1514501571655273 // batch_acc :: 0.1875 // batch_res :: 0.9152365922927856 \n",
            "batch_loss 6 :: 2.05368971824646 // batch_acc :: 0.25 // batch_res :: 0.9115449786186218 \n",
            "batch_loss 7 :: 1.9929007291793823 // batch_acc :: 0.3359375 // batch_res :: 0.9126442670822144 \n",
            "batch_loss 8 :: 2.0669023990631104 // batch_acc :: 0.32692310214042664 // batch_res :: 0.9096259474754333 \n",
            "\tTRAIN epoch = 15 / loss = 2.0566930770874023 / acc = 0.28600001335144043 / res = 0.9133318662643433\n",
            "\tVAL epoch = 15 / loss = 6.238107681274414 / acc = 0.14000000059604645 / res = 1.2261950969696045\n",
            "batch_loss 1 :: 2.0308971405029297 // batch_acc :: 0.2734375 // batch_res :: 0.9109984636306763 \n",
            "batch_loss 2 :: 2.0270795822143555 // batch_acc :: 0.2265625 // batch_res :: 0.9150629639625549 \n",
            "batch_loss 3 :: 2.047579765319824 // batch_acc :: 0.203125 // batch_res :: 0.911288321018219 \n",
            "batch_loss 4 :: 2.0536088943481445 // batch_acc :: 0.203125 // batch_res :: 0.9109686017036438 \n",
            "batch_loss 5 :: 2.0032529830932617 // batch_acc :: 0.234375 // batch_res :: 0.9216574430465698 \n",
            "batch_loss 6 :: 2.048163890838623 // batch_acc :: 0.2890625 // batch_res :: 0.9102219343185425 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-231-cc87eee9e93a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbroyden_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warmup\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-230-d01cfc0cef4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                                                         \u001b[0mx_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                                                         \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                                                         mode=mode)\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-230-d01cfc0cef4a>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(weights, opt_state, x_batch, y_true, mode)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mloss_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       ans, vjp_py, aux = _vjp(\n\u001b[0;32m--> 955\u001b[0;31m           f_partial, *dyn_args, has_aux=True, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m    956\u001b[0m     \u001b[0m_check_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0mtree_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_check_output_dtype_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholomorphic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_aux_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m     out_primal, out_vjp, aux = ad.vjp(\n\u001b[0;32m-> 2414\u001b[0;31m         flat_fun, primals_flat, has_aux=True, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2415\u001b[0m     \u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_aux_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m   \u001b[0mout_primal_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_primal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munbound_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    590\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_name_stack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-230-d01cfc0cef4a>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(weights, x_batch, y_true, mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdeq_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmdeqff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-227-f6c53d828b4f>\u001b[0m in \u001b[0;36mmdeq_fn\u001b[0;34m(x, encoder, decoder, deqff, all_weights, solver_fn, mode)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeqff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;31m# apply rootfinder with custom vjp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrootfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeqff_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeqff_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"direct_solver\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/custom_derivatives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mflat_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     out_flat = custom_vjp_call_p.bind(flat_fun, flat_fwd, flat_bwd, *args_flat,\n\u001b[0;32m--> 558\u001b[0;31m                                       out_trees=out_trees)\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0mfst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_linear_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfst\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/custom_derivatives.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, fwd, bwd, out_trees, *args)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0mbwd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     outs = top_trace.process_custom_vjp_call(self, fun, fwd, bwd_, tracers,\n\u001b[0;32m--> 643\u001b[0;31m                                              out_trees=out_trees)\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0mfst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_trace_todo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_linear_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_trace_todo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mprocess_custom_vjp_call\u001b[0;34m(self, _, __, fwd, bwd, tracers, out_trees)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mprimals_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangents_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtangent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mtangents_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstantiate_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangents_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mres_and_primals_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_and_primals_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_leaves\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-2c43f92df49b>\u001b[0m in \u001b[0;36m_rootfind_fwd\u001b[0;34m(solver_fn, f_fn, threshold, eps, weights, z, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m                       \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                       x: jnp.ndarray):\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrootfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# print(\"fwd residual\",jnp.linalg.norm(f_fn(weights,z,x)-z)/jnp.linalg.norm(z))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/custom_derivatives.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mflat_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     out_flat = custom_vjp_call_p.bind(flat_fun, flat_fwd, flat_bwd, *args_flat,\n\u001b[0;32m--> 558\u001b[0;31m                                       out_trees=out_trees)\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0mfst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_linear_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfst\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/custom_derivatives.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, fwd, bwd, out_trees, *args)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0mbwd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     outs = top_trace.process_custom_vjp_call(self, fun, fwd, bwd_, tracers,\n\u001b[0;32m--> 643\u001b[0;31m                                              out_trees=out_trees)\n\u001b[0m\u001b[1;32m    644\u001b[0m     \u001b[0mfst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_trace_todo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_linear_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_trace_todo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_custom_vjp_call\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbwd\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-2c43f92df49b>\u001b[0m in \u001b[0;36mrootfind\u001b[0;34m(solver_fn, f_fn, threshold, eps, weights, z, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m                  x: jnp.ndarray):\n\u001b[1;32m      9\u001b[0m     \u001b[0mf_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Its forward call (basically just calling it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-216-b306fe740833>\u001b[0m in \u001b[0;36mdirect_jax\u001b[0;34m(f, z0, x0, threshold, eps)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgz_norm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0mz_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m       \u001b[0mz_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m       \u001b[0mgz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_new\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0mgz_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-227-f6c53d828b4f>\u001b[0m in \u001b[0;36mdeqff_root\u001b[0;34m(_weights, _z, _x)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mdeqff_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# note: it's safe to pass the shape_tuple here (no tracers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeqff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;31m# apply rootfinder with custom vjp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrootfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeqff_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeqff_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m     )(variables, *args, **kwargs, rngs=rngs)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmutable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mscope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m       \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/transforms.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1164\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlinen_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_named_call\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_setup\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mprewrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m     \u001b[0mfn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mmethod_suffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'.{fn_name}'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfn_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'__call__'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mfilter_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-226-21b43d825540>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, z, x, shape_tuple)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mz_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcringy_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcringy_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# step 1: compute residual blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mbranch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-220-aa9b1a8cc9a8>\u001b[0m in \u001b[0;36mcringy_reshape\u001b[0;34m(in_vec, shape_list)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmy_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmy_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmy_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmy_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmy_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4251\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4252\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 4253\u001b[0;31m                  unique_indices, mode, fill_value)\n\u001b[0m\u001b[1;32m   4254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4255\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4289\u001b[0m   \u001b[0;31m# This adds np.newaxis/None dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4290\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4292\u001b[0m _Indexer = collections.namedtuple(\"_Indexer\", [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    849\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expand_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(array, dimensions)\u001b[0m\n\u001b[1;32m   1214\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0mresult_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m   \u001b[0mbroadcast_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AvrarhHIP7qM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}