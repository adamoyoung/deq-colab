{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deq-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66cb2fca213746b19d895d3bde966ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f391db9d2d44222a1f572aa0eeaa463",
              "IPY_MODEL_bd504ff1b65048eb90d2cf6aa5381bd3",
              "IPY_MODEL_64bb6a00bf9c4bee8e35cce0456ad39f"
            ],
            "layout": "IPY_MODEL_fa66105a99ad4c46bc9598ba5f58ba13"
          }
        },
        "2f391db9d2d44222a1f572aa0eeaa463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afcb61ee4f13479792a45dd9434cced9",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5a870a35dd4dcca5e86642cab5ece0",
            "value": ""
          }
        },
        "bd504ff1b65048eb90d2cf6aa5381bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_724b8c3bc6044dfab63dc7b98d811b67",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f042874d86364d92aeb8130b3ad4b53f",
            "value": 170498071
          }
        },
        "64bb6a00bf9c4bee8e35cce0456ad39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edb4c78b9f4c4cad8f25a92b7a0a0514",
            "placeholder": "​",
            "style": "IPY_MODEL_2152f59baec645c49e672f2e7c5f5e7b",
            "value": " 170499072/? [00:01&lt;00:00, 91974764.57it/s]"
          }
        },
        "fa66105a99ad4c46bc9598ba5f58ba13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcb61ee4f13479792a45dd9434cced9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5a870a35dd4dcca5e86642cab5ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "724b8c3bc6044dfab63dc7b98d811b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f042874d86364d92aeb8130b3ad4b53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edb4c78b9f4c4cad8f25a92b7a0a0514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2152f59baec645c49e672f2e7c5f5e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install flax optax"
      ],
      "metadata": {
        "id": "si6WmYzuEMsO",
        "outputId": "15f740bf-1783-45ed-a0bd-2c452ecb4431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flax\n",
            "  Downloading flax-0.4.1-py3-none-any.whl (184 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 38.6 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 40 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 61 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 71 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 81 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 102 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 112 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 122 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 133 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 143 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 153 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 163 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 174 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184 kB 28.7 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.1-py3-none-any.whl (136 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 46.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 48.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61 kB 57.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71 kB 59.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 81 kB 59.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92 kB 61.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102 kB 63.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 112 kB 63.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 122 kB 63.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 133 kB 63.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 136 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.21.5)\n",
            "Requirement already satisfied: jax>=0.3 in /usr/local/lib/python3.7/dist-packages (from flax) (0.3.4)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.3->flax) (3.3.0)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.2+cuda11.cudnn805)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.3->flax) (1.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.4.0)\n",
            "Installing collected packages: chex, optax, flax\n",
            "Successfully installed chex-0.1.1 flax-0.4.1 optax-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ukan3mN8mwVX"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "import jax.lax as lax\n",
        "\n",
        "import optax\n",
        "\n",
        "import flax\n",
        "from flax import linen as nn\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import numpy as np  # TO DO remove np's -> jnp\n",
        "import contextlib\n",
        "\n",
        "from typing import Tuple, Union, List, OrderedDict, Callable\n",
        "from dataclasses import field\n",
        "\n",
        "# jaxopt has already implicit differentiation!!\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function for local random seeding\n",
        "@contextlib.contextmanager\n",
        "def np_temp_seed(seed):\n",
        "\tstate = np.random.get_state()\n",
        "\tnp.random.seed(seed)\n",
        "\ttry:\n",
        "\t\tyield\n",
        "\tfinally:\n",
        "\t\tnp.random.set_state(state)"
      ],
      "metadata": {
        "id": "aIIhg_O_xVGC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _safe_norm_jax(v):\n",
        "    if not jnp.all(jnp.isfinite(v)):\n",
        "        return jnp.inf\n",
        "    return jnp.linalg.norm(v)\n",
        "\n",
        "def scalar_search_armijo_jax(phi, phi0, derphi0, c1=1e-4, alpha0=1, amin=0):\n",
        "    ite = 0\n",
        "    phi_a0 = phi(alpha0)    # First do an update with step size 1\n",
        "    if phi_a0 <= phi0 + c1*alpha0*derphi0:\n",
        "        return alpha0, phi_a0, ite\n",
        "\n",
        "    # Otherwise, compute the minimizer of a quadratic interpolant\n",
        "    alpha1 = -(derphi0) * alpha0**2 / 2.0 / (phi_a0 - phi0 - derphi0 * alpha0)\n",
        "    phi_a1 = phi(alpha1)\n",
        "\n",
        "    # Otherwise loop with cubic interpolation until we find an alpha which\n",
        "    # satisfies the first Wolfe condition (since we are backtracking, we will\n",
        "    # assume that the value of alpha is not too small and satisfies the second\n",
        "    # condition.\n",
        "    while alpha1 > amin:       # we are assuming alpha>0 is a descent direction\n",
        "        factor = alpha0**2 * alpha1**2 * (alpha1-alpha0)\n",
        "        a = alpha0**2 * (phi_a1 - phi0 - derphi0*alpha1) - \\\n",
        "            alpha1**2 * (phi_a0 - phi0 - derphi0*alpha0)\n",
        "        a = a / factor\n",
        "        b = -alpha0**3 * (phi_a1 - phi0 - derphi0*alpha1) + \\\n",
        "            alpha1**3 * (phi_a0 - phi0 - derphi0*alpha0)\n",
        "        b = b / factor\n",
        "\n",
        "        alpha2 = (-b + jnp.sqrt(jnp.abs(b**2 - 3 * a * derphi0))) / (3.0*a)\n",
        "        phi_a2 = phi(alpha2)\n",
        "        ite += 1\n",
        "\n",
        "        if (phi_a2 <= phi0 + c1*alpha2*derphi0):\n",
        "            return alpha2, phi_a2, ite\n",
        "\n",
        "        if (alpha1 - alpha2) > alpha1 / 2.0 or (1 - alpha2/alpha1) < 0.96:\n",
        "            alpha2 = alpha1 / 2.0\n",
        "\n",
        "        alpha0 = alpha1\n",
        "        alpha1 = alpha2\n",
        "        phi_a0 = phi_a1\n",
        "        phi_a1 = phi_a2\n",
        "\n",
        "    # Failed to find a suitable step length\n",
        "    return None, phi_a1, ite\n",
        "\n",
        "\n",
        "def line_search_jax(update, x0, g0, g, nstep=0, on=True):\n",
        "    \"\"\"\n",
        "    `update` is the propsoed direction of update.\n",
        "\n",
        "    Code adapted from scipy.\n",
        "    \"\"\"\n",
        "    tmp_s = [0]\n",
        "    tmp_g0 = [g0]\n",
        "    tmp_phi = [jnp.linalg.norm(g0)**2]\n",
        "    s_norm = jnp.linalg.norm(x0) / jnp.linalg.norm(update)\n",
        "\n",
        "    def phi(s, store=True):\n",
        "        if s == tmp_s[0]:\n",
        "            return tmp_phi[0]    # If the step size is so small... just return something\n",
        "        x_est = x0 + s * update\n",
        "        g0_new = g(x_est)\n",
        "        phi_new = _safe_norm_jax(g0_new)**2\n",
        "        if store:\n",
        "            tmp_s[0] = s\n",
        "            tmp_g0[0] = g0_new\n",
        "            tmp_phi[0] = phi_new\n",
        "        return phi_new\n",
        "    \n",
        "    if on:\n",
        "        s, phi1, ite = scalar_search_armijo_jax(phi, tmp_phi[0], -tmp_phi[0], amin=1e-2)\n",
        "    if (not on) or s is None:\n",
        "        s = 1.0\n",
        "        ite = 0\n",
        "\n",
        "    x_est = x0 + s * update\n",
        "    if s == tmp_s[0]:\n",
        "        g0_new = tmp_g0[0]\n",
        "    else:\n",
        "        g0_new = g(x_est)\n",
        "    return x_est, g0_new, x_est - x0, g0_new - g0, ite\n",
        "\n"
      ],
      "metadata": {
        "id": "F9GgbTf2Vbt_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmatvec_jax(part_Us, part_VTs, x):\n",
        "    # Compute x^T(-I + UV^T)\n",
        "    # x: (N, 2d, L')\n",
        "    # part_Us: (N, 2d, L', threshold)\n",
        "    # part_VTs: (N, threshold, 2d, L')\n",
        "    if jnp.size(part_Us) == 0:\n",
        "        return -x\n",
        "    xTU = jnp.einsum('bij, bijd -> bd', x, part_Us)   # (N, threshold)\n",
        "    return -x + jnp.einsum('bd, bdij -> bij', xTU, part_VTs)    # (N, 2d, L'), but should really be (N, 1, (2d*L'))\n",
        "\n",
        "def matvec_jax(part_Us, part_VTs, x):\n",
        "    # Compute (-I + UV^T)x\n",
        "    # x: (N, 2d, L')\n",
        "    # part_Us: (N, 2d, L', threshold)\n",
        "    # part_VTs: (N, threshold, 2d, L')\n",
        "    if jnp.size(part_Us) == 0:\n",
        "        return -x\n",
        "    VTx = jnp.einsum('bdij, bij -> bd', part_VTs, x)  # (N, threshold)\n",
        "    return -x + jnp.einsum('bijd, bd -> bij', part_Us, VTx)     # (N, 2d, L'), but should really be (N, (2d*L'), 1)\n"
      ],
      "metadata": {
        "id": "DpQtBBHPV36I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def broyden_jax(f, x0, threshold, eps=1e-3, stop_mode=\"rel\", ls=False, name=\"unknown\"):\n",
        "    bsz, total_hsize, seq_len = x0.shape\n",
        "    g = lambda y: f(y) - y\n",
        "    dev = x0.device()\n",
        "    alternative_mode = 'rel' if stop_mode == 'abs' else 'abs'\n",
        "    \n",
        "    x_est = x0           # (bsz, 2d, L')\n",
        "    gx = g(x_est)        # (bsz, 2d, L')\n",
        "    nstep = 0\n",
        "    tnstep = 0\n",
        "    \n",
        "    # For fast calculation of inv_jacobian (approximately)\n",
        "    Us = jax.device_put(jnp.zeros((bsz, total_hsize, seq_len, threshold)),dev)     # One can also use an L-BFGS scheme to further reduce memory\n",
        "    VTs = jax.device_put(jnp.zeros((bsz, threshold, total_hsize, seq_len)),dev)\n",
        "    update = -matvec_jax(Us[:,:,:,:nstep], VTs[:,:nstep], gx)      # Formally should be -torch.matmul(inv_jacobian (-I), gx)\n",
        "    prot_break = False\n",
        "    \n",
        "    # To be used in protective breaks\n",
        "    protect_thres = (1e6 if stop_mode == \"abs\" else 1e3) * seq_len\n",
        "    new_objective = 1e8\n",
        "\n",
        "    trace_dict = {'abs': [],\n",
        "                  'rel': []}\n",
        "    lowest_dict = {'abs': 1e8,\n",
        "                   'rel': 1e8}\n",
        "    lowest_step_dict = {'abs': 0,\n",
        "                        'rel': 0}\n",
        "    nstep, lowest_xest, lowest_gx = 0, x_est, gx\n",
        "\n",
        "    while nstep < threshold:\n",
        "        x_est, gx, delta_x, delta_gx, ite = line_search_jax(update, x_est, gx, g, nstep=nstep, on=ls)\n",
        "        nstep += 1\n",
        "        tnstep += (ite+1)\n",
        "        abs_diff = jnp.linalg.norm(gx)\n",
        "        rel_diff = abs_diff / (jnp.linalg.norm(gx + x_est) + 1e-9)\n",
        "        diff_dict = {'abs': abs_diff,\n",
        "                     'rel': rel_diff}\n",
        "        trace_dict['abs'].append(abs_diff)\n",
        "        trace_dict['rel'].append(rel_diff)\n",
        "        for mode in ['rel', 'abs']:\n",
        "            if diff_dict[mode] < lowest_dict[mode]:\n",
        "                if mode == stop_mode: \n",
        "                    lowest_xest, lowest_gx = lax.stop_gradient(x_est.copy()), lax.stop_gradient(gx.copy())\n",
        "                lowest_dict[mode] = diff_dict[mode]\n",
        "                lowest_step_dict[mode] = nstep\n",
        "\n",
        "        new_objective = diff_dict[stop_mode]\n",
        "        if new_objective < eps: break\n",
        "        if new_objective < 3*eps and nstep > 30 and np.max(trace_dict[stop_mode][-30:]) / np.min(trace_dict[stop_mode][-30:]) < 1.3:\n",
        "            # if there's hardly been any progress in the last 30 steps\n",
        "            break\n",
        "        if new_objective > trace_dict[stop_mode][0] * protect_thres:\n",
        "            prot_break = True\n",
        "            break\n",
        "\n",
        "        part_Us, part_VTs = Us[:,:,:,:nstep-1], VTs[:,:nstep-1]\n",
        "        vT = rmatvec_jax(part_Us, part_VTs, delta_x)\n",
        "        u = (delta_x - matvec_jax(part_Us, part_VTs, delta_gx)) / jnp.einsum('bij, bij -> b', vT, delta_gx)[:,None,None]\n",
        "        vT = jnp.nan_to_num(vT,nan=0.)\n",
        "        u = jnp.nan_to_num(u,nan=0.)\n",
        "        VTs = VTs.at[:,nstep-1].set(vT)\n",
        "        Us = Us.at[:,:,:,nstep-1].set(u)\n",
        "        update = -matvec_jax(Us[:,:,:,:nstep], VTs[:,:nstep], gx)\n",
        "\n",
        "    # Fill everything up to the threshold length\n",
        "    for _ in range(threshold+1-len(trace_dict[stop_mode])):\n",
        "        trace_dict[stop_mode].append(lowest_dict[stop_mode])\n",
        "        trace_dict[alternative_mode].append(lowest_dict[alternative_mode])\n",
        "\n",
        "    return {\"result\": lowest_xest,\n",
        "            \"lowest\": lowest_dict[stop_mode],\n",
        "            \"nstep\": lowest_step_dict[stop_mode],\n",
        "            \"prot_break\": prot_break,\n",
        "            \"abs_trace\": trace_dict['abs'],\n",
        "            \"rel_trace\": trace_dict['rel'],\n",
        "            \"eps\": eps,\n",
        "            \"threshold\": threshold}\n",
        "\n",
        "\n",
        "def newton_jax(f, x0, threshold, eps=1e-3, stop_mode=\"rel\", name=\"unknown\"):\n",
        "\n",
        "    g = lambda y: f(y) - y\n",
        "    jac_g = jax.jacfwd(g)\n",
        "    x = x0\n",
        "    gx = g(x)\n",
        "    gx_norm = jnp.linalg.norm(gx)\n",
        "    nstep = 0\n",
        "    # print(gx_norm)\n",
        "\n",
        "    while nstep < threshold:\n",
        "      # solve system\n",
        "      delta_x = jnp.linalg.solve(jac_g(x),-g(x))\n",
        "      x = x + delta_x\n",
        "      gx = g(x)\n",
        "      gx_norm = jnp.linalg.norm(gx)\n",
        "      nstep += 1\n",
        "      # print(gx_norm)\n",
        "\n",
        "    return x, gx, gx_norm"
      ],
      "metadata": {
        "id": "JDts6pYBWEpv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MDEQBlock(nn.Module):\n",
        "    input: jnp.DeviceArray\n",
        "    input_dim: int = 8\n",
        "    hidden_dim: int = 2*input_dim\n",
        "    kernel_size: Tuple[int] = (3, 3)  # can also be (5, 5), modify later\n",
        "    num_groups: int = 2\n",
        "    curr_branch: int = 0\n",
        "    \n",
        "    def setup(self, i, num_channels):  \n",
        "        self.input_dim = num_channels\n",
        "        self.hidden_dim =  2*self.input_dim\n",
        "        self.curr_branch = i\n",
        "\n",
        "        # init-substitute for flax\n",
        "        self.conv1 = nn.Conv(features=self.hidden_dim, kernel_size=self.kernel_size, strides=1)\n",
        "        self.group1 = nn.GroupNorm(num_groups=self.num_groups, group_size=self.hidden_dim)\n",
        "        self.relu = nn.relu()\n",
        "        self.conv2 = nn.Conv(features=self.input_dim, kernel_size=self.kernel_size, strides=1)\n",
        "        self.group2 = nn.GroupNorm(num_groups=self.num_groups, group_size=self.input_dim)\n",
        "        self.group3 = nn.GroupNorm(num_groups=self.num_groups, group_size=self.input_dim)\n",
        "\n",
        "\n",
        "    def __call__(self, x, branch, injection):\n",
        "        # forward pass\n",
        "        h1 = self.group1(self.conv1(x))\n",
        "        h1 = self.relu(h1)\n",
        "        \n",
        "        h2 = self.conv2(z)\n",
        "        if branch == 0:\n",
        "            h2 += injection\n",
        "        h2 = self.group2(h2)\n",
        "        h2 += x\n",
        "        \n",
        "        h3 = self.relu(h2)\n",
        "        out = self.group3(h3)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    \n",
        "''' \n",
        "    assert statement we'll need    \n",
        "    assert that the number of branches == len(input_channel_vector)\n",
        "    assert also that num_branches == len(kernel_size_vector)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EzcfTWz6agE_",
        "outputId": "21b97dbd-61a2-437b-be6a-41b3a293b319"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n    assert statement we'll need    \\n    assert that the number of branches == len(input_channel_vector)\\n    assert also that num_branches == len(kernel_size_vector)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "    def setup(self, branches, channel_dimensions, num_groups):\n",
        "        self.in_chan, self.out_chan = channel_dimensions\n",
        "        self.num_groups = num_groups\n",
        "\n",
        "    def _downsample(self, branches):\n",
        "        from_res, to_res = branches  # sampling from resolution from_res to to_res\n",
        "        num_samples = to_res - from_res\n",
        "        assert num_samples > 0\n",
        "\n",
        "        down_block = []\n",
        "\n",
        "        for n in range(len(num_samples)):\n",
        "            inter_chan = self.in_chan if n < num_samples-1 else self.out_chan\n",
        "            conv_down = nn.Conv(features=inter_chan, kernel_size=3, strides=2, padding=1,\n",
        "                               bias=False)\n",
        "            group_down = nn.GroupNorm(num_groups=self.num_groups,\n",
        "                                      group_size=inter_chan)\n",
        "            relu_down = nn.relu()\n",
        "            module_list = [conv_down, group_down]\n",
        "            if n < num_samples - 1:\n",
        "                module = nn.Sequential([conv_down,\n",
        "                                        group_down,\n",
        "                                        relu_down])\n",
        "            else:\n",
        "                module = nn.Sequential([conv_down,\n",
        "                                        group_down])\n",
        "            down_block.append(module)\n",
        "        return nn.Sequential(down_block)\n",
        "\n",
        "    def __call__(self, branches, z_plus):\n",
        "        downsample = self._downsample(branches)\n",
        "        return downsample(z_plus)\n"
      ],
      "metadata": {
        "id": "1fO-Bsnly9Jp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "    def setup(self, channel_dimensions, num_groups):\n",
        "        self.in_chan, self.out_chan = channel_dimensions\n",
        "        self.num_groups = num_groups\n",
        "\n",
        "    def _upsample(self, branches):\n",
        "        from_res, to_res = branches  # sampling from resolution from_res to to_res\n",
        "        num_samples = from_res - to_res\n",
        "        assert num_samples > 0\n",
        "\n",
        "        inter_chan = self.in_chan if n < num_samples-1 else self.out_chan\n",
        "        return [nn.Conv(features=self.out_chan, kernel_size=1, bias=False),\n",
        "                        nn.GroupNorm(num_groups=self.num_groups, group_size=inter_chan),\n",
        "                        nn.Upsample(scale_factor=2**num_samples)]\n",
        "            \n",
        "\n",
        "    def __call__(self, branches, z_plus):\n",
        "        upsample = self._upsample(branches)\n",
        "        return upsample(z_plus)"
      ],
      "metadata": {
        "id": "pApLGNTRK8OW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class f_theta(nn.Module):\n",
        "    features: Tuple[int] = (16, 4)\n",
        "    num_groups: int = 8\n",
        "    channels: List[int] = field(default_factory=lambda:[24, 24, 24])\n",
        "    # branches: List[int] = field(default_factory=lambda:[24, 24, 24])\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        self.res_block = MDEQBlock()\n",
        "        self.downsample = DownSample(channel_dimensions=self.channels,\n",
        "                                     num_groups=self.num_groups)\n",
        "        self.upsample = UpSample(channel_dimensions=self.channels,\n",
        "                                 num_groups=self.num_groups)\n",
        "\n",
        "        self.branches = self.stack_branches()\n",
        "        self.num_branches = len(self.branches)\n",
        "\n",
        "        self.fuse_branches = self.fuse()\n",
        "        self.transform = self.transform_output()\n",
        "\n",
        "    def stack_branches(self):\n",
        "        branches = []\n",
        "        for i in self.num_branches:\n",
        "          branches.append(MDEQBlock(i, self.channels[i]))\n",
        "        return branches\n",
        "\n",
        "    def fuse(self, z_plus, channel_dimensions):\n",
        "        # up- and downsampling stuff\n",
        "        # z_plus: output of residual block\n",
        "        if self.num_branches == 1:\n",
        "            return None\n",
        "        out = 1\n",
        "        fuse_layers = []\n",
        "        for i in range(self.num_branches):\n",
        "            array = []\n",
        "            for j in range(self.num_branches):\n",
        "                if i == j:\n",
        "                    array.append(z_plus[i])\n",
        "                else:\n",
        "                    if i < j:\n",
        "                        sampled = self.downsample(z_plus=z_plus, branches=(i, j),\n",
        "                                                 channel_dimension=channel_dimensions)\n",
        "                    elif i > j:\n",
        "                        sampled = self.upsample(z_plus=z_plus, branches=(i, j),\n",
        "                                                 channel_dimension=channel_dimensions)\n",
        "                    array.append(nn.Module(sampled))\n",
        "            # fuse_layers.append(nn.Module(array))\n",
        "            fuse_layers.append(array)\n",
        "\n",
        "        return fuse_layers\n",
        "    \n",
        "    def transform_output(self):\n",
        "        transforms = []\n",
        "        for i in range(self.num_branches):\n",
        "          transforms.append(nn.Sequential([nn.relu(),\n",
        "                                          nn.Conv(features=self.channels[i], kernel_size=1, bias=False),\n",
        "                                          nn.GroupNorm(num_groups=self.num_groups//2,\n",
        "                                                       group_size=self.channels[i])]))\n",
        "        \n",
        "        return transforms\n",
        "\n",
        "    def __call__(self, x, injection):\n",
        "        # step 1: compute residual blocks\n",
        "        branch_outputs = []\n",
        "        for i in range(self.num_branches):\n",
        "            branch_outputs.append(self.branches[i](x[i], i, injection[i])) # z, branch, x\n",
        "\n",
        "        # step 2: fuse residual blocks\n",
        "        fuse_outputs = []\n",
        "        for i in range(self.num_branches):\n",
        "          intermediate_i = 0\n",
        "          for j in range(self.num_branches):\n",
        "            if i == j:\n",
        "              intermediate_i += branch_outputs[i]\n",
        "            else:\n",
        "              intermediate_i += self.fuse[i][j](branch_outputs[j])\n",
        "          fuse_outputs.append(self.transform[i](intermediate_i))\n",
        "\n",
        "        return fuse_outputs\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "dWkUS52WoaiC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MDEQModel(nn.Module):\n",
        "    features: Tuple[int] = (16, 4)\n",
        "    num_branches: int = 3\n",
        "    num_groups: int = 8\n",
        "    channels: List[int] = field(default_factory=lambda:[24,24,24])\n",
        "    branches: List[int] = field(default_factory=lambda:[1,1,1])\n",
        "    training: bool = True\n",
        "    solver_fn: Callable = broyden_jax\n",
        "\n",
        "    def setup(self):\n",
        "        self.num_branches = len(self.branches)\n",
        "        self.transform = [nn.Sequential(OrderedDict([(nn.Conv(features=self.channels[i], kernel_size=3, stride=1)),\n",
        "                                       (nn.BatchNorm()),\n",
        "                                       (nn.relu()),\n",
        "                                       (nn.Conv(features=self.channels[i], kernel_size=3, stride=1)),\n",
        "                                       (nn.BatchNorm()),\n",
        "                                       (nn.relu())])) for i in range(self.num_branches)]\n",
        "        self.model = f_theta()\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        x = self.transform(x)\n",
        "        x_list = [x]\n",
        "        for i in range(self.num_branches):\n",
        "            bs, _, H, W = x_list[-1].shape\n",
        "            x_list.append(np.zeros(bs, self.channels[i], H//2, W//2))\n",
        "        z_list = [np.zeros(elem) for elem in x_list]\n",
        "\n",
        "        bsz = x.shape[0]\n",
        "        func = lambda z: self.model(z_list, x_list)\n",
        "        z_vec = jnp.cat([elem.reshape(bsz, -1, 1) for elem in z_list], dim=1)\n",
        "        result = self.solver(func, z_vec, threshold=0.001)\n",
        "        z_vec = result['result']\n",
        "        output = z_vec\n",
        "        if self.training:\n",
        "            output = func(z_vec.requires_grad_())\n",
        "        # jac_loss = jac_loss_estimate(output, z1) # comes from the follow-up paper\n",
        "        jac_loss = None\n",
        "        \n",
        "        y_list = output # TO DO -- for now without dropout!\n",
        "        return y_list, jac_loss"
      ],
      "metadata": {
        "id": "ozN6cMheafUj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(image, label, num_classes=10):\n",
        "    image = jnp.float32(image) / 255.\n",
        "    label = jax.nn.one_hot(label, num_classes=num_classes)\n",
        "    return image, label\n",
        "\n",
        "def load_data():\n",
        "    test_ds = torchvision.datasets.CIFAR10(root=\"data\", train=False,download=True)\n",
        "    train_ds = torchvision.datasets.CIFAR10(root=\"data\", train=True,download=True)\n",
        "\n",
        "    train_images, train_labels = transform(train_ds.data[:1000], train_ds.targets[:1000])\n",
        "    test_images, test_labels = transform(test_ds.data[:200], test_ds.targets[:200])\n",
        "    return train_images, train_labels, test_images, test_labels"
      ],
      "metadata": {
        "id": "qCtrgYH-K2b8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    '''\n",
        "    extra thing: warm-up using gradient descent in pytorch code of official repo\n",
        "    --> check impact of that and maybe also cost etc (eg if only one layer etc)\n",
        "    '''\n",
        "\n",
        "    max_itr = 1000\n",
        "    print_interval = 100\n",
        "\n",
        "    data = load_data()\n",
        "    solver_fn = broyden_jax\n",
        "    my_deq = MDEQModel(solver_fn=solver_fn)\n",
        "\n",
        "    # def cross_entropy_loss(*, logits, labels):\n",
        "    def cross_entropy_loss(logits, labels):\n",
        "        ''' \n",
        "        should be same as  optax.softmax_cross_entropy(logits, labels); \n",
        "        if getting funny results maybe remove log of logits\n",
        "        '''\n",
        "        one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
        "        return -jnp.mean(jnp.sum(one_hot_labels * jnp.log(logits), axis=-1))\n",
        "\n",
        "    png = jax.random.PRNGKey(0)\n",
        "    _, key = jax.random.split(png, 2)\n",
        "    init = jax.nn.initializers.glorot_normal()\n",
        "    #init_weights = init(key, (shape of weights), jnp.float64)\n",
        "    # x0 = random.glorot_normal(key, shape=(1,))\n",
        "\n",
        "    weights = my_deq.init(rngs=png, method=init)\n",
        "    optimizer = optax.adamw(learning_rate=0.001, weight_decay=0.001)\n",
        "    opt_state = optimizer.init(weights)\n",
        "\n",
        "    loss = cross_entropy_loss\n",
        "\n",
        "    def step(weights, opt_state, x_batch, y_true):\n",
        "        loss_vals, grad = jax.value_and_grad(loss, has_aux=True)(weights, x_batch, y_true)\n",
        "        updates, opt_state = optimizer.update(grad, opt_state, weights)\n",
        "        weights = optax.apply_updates(weights, updates)\n",
        "        return weights, opt_state, loss_vals\n",
        "\n",
        "    data_size = data.shape[0]\n",
        "    batch_size = 100\n",
        "\n",
        "    def generator(batch_size: int=10):\n",
        "        ''' https://optax.readthedocs.io/en/latest/meta_learning.html?highlight=generator#meta-learning '''\n",
        "        rng = jax.random.PRNGKey(0)\n",
        "\n",
        "        while True:\n",
        "            rng, k1 = jax.random.split(rng, num=2)\n",
        "            idxs = jax.random.uniform(k1, shape=(batch_size), minval=0, maxval=data_size, dtype=jnp.int32)\n",
        "            yield idxs\n",
        "\n",
        "    g = generator(batch_size=batch_size)\n",
        "\n",
        "    for itr in range(max_itr):\n",
        "        batch_idxs = next(g)\n",
        "        x_batch = data[batch_idxs]\n",
        "        params, opt_state, loss_vals = step(params, opt_state, x_batch)\n",
        "        \n",
        "        if itr % print_interval == 0:\n",
        "            print(\"\\tat step\", itr, \"have loss\", loss_vals)\n",
        "\n",
        "        if loss_vals < 1e-5:\n",
        "            break\n",
        "    "
      ],
      "metadata": {
        "id": "S_3FNBfqojTY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "FQh6WBQmokr8",
        "outputId": "9408bf3c-35fc-41ab-cb5e-f2572b1fd362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "66cb2fca213746b19d895d3bde966ce8",
            "2f391db9d2d44222a1f572aa0eeaa463",
            "bd504ff1b65048eb90d2cf6aa5381bd3",
            "64bb6a00bf9c4bee8e35cce0456ad39f",
            "fa66105a99ad4c46bc9598ba5f58ba13",
            "afcb61ee4f13479792a45dd9434cced9",
            "1f5a870a35dd4dcca5e86642cab5ece0",
            "724b8c3bc6044dfab63dc7b98d811b67",
            "f042874d86364d92aeb8130b3ad4b53f",
            "edb4c78b9f4c4cad8f25a92b7a0a0514",
            "2152f59baec645c49e672f2e7c5f5e7b"
          ]
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66cb2fca213746b19d895d3bde966ce8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-d9a935b32778>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglorot_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breakdown of code overall:\n",
        "\n",
        "\n",
        "*   MDEQ modul\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "7RvQXU3CROAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wNA8y6PdRdZr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}